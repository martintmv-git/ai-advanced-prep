<html><head><style>body {
   color: black;
}
</style></head><body><h1 id="-chess-pieces-detection-grad-cam">♟️ Chess Pieces Detection - Grad-CAM</h1>
<p>Author: <a href="https://martintomov.com">Martin Tomov</a> - @martintmv</p>
<p>Dataset: <a href="https://www.kaggle.com/datasets/anshulmehtakaggl/chess-pieces-detection-images-dataset">Kaggle Chess Pieces Detection</a></p>
<p>The dataset chosen for this assignment is a collection of 651 chess piece images, sourced from Kaggle&#39;s &quot;Chess Pieces Detection Images Dataset&quot;.</p>
<p>This notebook was created in Google Colab in attempt to utilise the new L4 GPU.</p>
<h4 id="-why-the-chess-pieces-dataset-is-suitable-for-cnns-">❓ Why the Chess Pieces Dataset is Suitable for CNNs?</h4>
<p>1️⃣. Variety of Classes: It includes images categorised into five different chess pieces - Pawn, Queen, Rook, Bishop, and Knight. This variety allows for a comprehensive classification challenge.</p>
<p>2️⃣. Real-world Application: Chess piece recognition is a cool real-world task. It&#39;s useful for analyzing games, online chess platforms, and educational tools.</p>
<p>3️⃣. Dataset Size and Complexity: This size is manageable yet sufficiently challenging for training a robust model, making it ideal for educational purposes and for demonstrating the effectiveness of transfer learning where the model leverages pre-learned patterns from a larger dataset.</p>
<h4 id="-approach">❓ Approach</h4>
<p>Given the dataset&#39;s characteristics, my approach will leverage a pre-trained Convolutional Neural Network (CNN), specifically the VGG16 model, known for its performance in image classification tasks. The VGG16 model, pre-trained on the ImageNet dataset, provides a robust set of features for image recognition that we can fine-tune for our specific task of chess piece classification.</p>
<p>1️⃣. Preprocessing: Making images ready for the model by resizing and adjusting them.</p>
<p>2️⃣. Customizing the Model: Add some new layers on top of VGG16 to make it work for recognizing chess pieces. These new layers help the model understand our specific task better.</p>
<p>3️⃣. Training, Testing and Evaluating Performance: Train the model and check how well it&#39;s doing using K-Fold cross-validation. This helps to make sure the model works well with new images too. Next, a confusion matrix to see how well the model recognizes each chess piece. Finally, show some example images to see where the model does well and where it needs improvement.</p>
<h4 id="-why-vgg16-and-not-vgg19">❓ Why VGG16 and not VGG19</h4>
<p>The primary differnece between VGG16 and VGG19 lies in the number of layers, where VGG19 is more complex but may face challenges related to overfitting compared to the slightly simpler yet high-performing VGG16 architecture. VGG16 tends to perform better than VGG19 for smaller datasets. The simplicity of VGG16 makes it more suitable for smaller datasets, as it is less prone to overfitting compared to VGG19.</p>
<h1 id="step-1-imports">Step 1. Imports</h1>
<p>First, I need to import necessary libraries.</p>
<pre><code class="lang-python"><span class="hljs-meta"># Importing libraries</span>
<span class="hljs-meta"># ------------------------</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> sklearn
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> pathlib
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns

<span class="hljs-title">from</span> google.colab <span class="hljs-keyword">import</span> drive
<span class="hljs-title">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> KFold, train_test_split
<span class="hljs-title">from</span> tensorflow <span class="hljs-keyword">import</span> keras
<span class="hljs-title">from</span> tensorflow.keras <span class="hljs-keyword">import</span> Sequential
<span class="hljs-title">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Dropout,Flatten,Dense,BatchNormalization
<span class="hljs-title">from</span> tensorflow.keras.preprocessing.image <span class="hljs-keyword">import</span> ImageDataGenerator
<span class="hljs-title">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix
</code></pre>
<h1 id="step-2-load-data-with-pandas">Step 2. Load Data with Pandas</h1>
<p>In this step, I&#39;m loading the dataset from my Google Drive. The dataset consists of images of chess pieces, and we&#39;re interested in the type of piece each image represents.</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path
drive.mount(<span class="hljs-string">'/content/drive'</span>)

<span class="hljs-comment"># Define the path to the dataset</span>
data_path = Path(<span class="hljs-string">'/content/drive/MyDrive/chessdata'</span>)

<span class="hljs-comment"># Collect all jpg image paths</span>
img_paths = list(data_path.glob(<span class="hljs-string">'**/*.jpg'</span>))

<span class="hljs-comment"># Extract labels from the path</span>
img_labels = [path.parent.name <span class="hljs-keyword">for</span> path <span class="hljs-keyword">in</span> img_paths]

<span class="hljs-comment"># Create a DataFrame</span>
img_df = pd.DataFrame({
    <span class="hljs-string">'Path'</span>: img_paths,
    <span class="hljs-string">'Label'</span>: img_labels
})

<span class="hljs-comment"># Shuffle the DataFrame to ensure a good mix of data points</span>
img_df = img_df.sample(frac=<span class="hljs-number">1</span>).reset_index(drop=<span class="hljs-keyword">True</span>)

<span class="hljs-comment"># Display the first few entries of the DataFrame</span>
print(img_df.head())
</code></pre>
<pre><code>Mounted at <span class="hljs-regexp">/content/</span>drive
                                                Path           Label
<span class="hljs-number">0</span>  <span class="hljs-regexp">/content/</span>drive<span class="hljs-regexp">/MyDrive/</span>chessdata<span class="hljs-regexp">/Rook-resize/</span><span class="hljs-number">0.</span>..     Rook-resize
<span class="hljs-number">1</span>  <span class="hljs-regexp">/content/</span>drive<span class="hljs-regexp">/MyDrive/</span>chessdata/bishop_resize...  bishop_resized
<span class="hljs-number">2</span>  <span class="hljs-regexp">/content/</span>drive<span class="hljs-regexp">/MyDrive/</span>chessdata/bishop_resize...  bishop_resized
<span class="hljs-number">3</span>  <span class="hljs-regexp">/content/</span>drive<span class="hljs-regexp">/MyDrive/</span>chessdata/knight-resize...   knight-resize
<span class="hljs-number">4</span>  <span class="hljs-regexp">/content/</span>drive<span class="hljs-regexp">/MyDrive/</span>chessdata<span class="hljs-regexp">/pawn_resized/</span>...    pawn_resized
</code></pre><h3 id="explore-data-distribution">Explore Data Distribution</h3>
<p>Before diving into model building, it&#39;s crucial to understand the distribution of classes in our dataset. Here, I visualize the frequency of each chess piece class to ensure that our model isn&#39;t biased towards any particular class during training. A balanced dataset helps in creating a model that performs equally well across all classes.</p>
<pre><code class="lang-python"><span class="hljs-comment"># Count the number of images per label</span>
label_counts = img_df[<span class="hljs-string">'Label'</span>].value_counts()
<span class="hljs-literal">print</span>(label_counts)

<span class="hljs-comment"># Visualize the distribution of classes</span>
label_counts.plot(kind=<span class="hljs-string">'bar'</span>)
plt.title(<span class="hljs-string">'Distribution of Chess Piece Classes'</span>)
plt.xlabel(<span class="hljs-string">'Class'</span>)
plt.ylabel(<span class="hljs-string">'Frequency'</span>)
plt.<span class="hljs-literal">show</span>()
</code></pre>
<pre><code>Label
knight-<span class="hljs-built_in">resize</span>     <span class="hljs-number">174</span>
bishop_resized    <span class="hljs-number">141</span>
Rook-<span class="hljs-built_in">resize</span>       <span class="hljs-number">139</span>
Queen-Resized     <span class="hljs-number">115</span>
pawn_resized       <span class="hljs-number">82</span>
<span class="hljs-built_in">Name</span>: <span class="hljs-built_in">count</span>, dtype: int64
</code></pre><p><img src="https://i.imgur.com/dfjgLbR.png" alt="png"></p>
<h3 id="visualize-sample-images">Visualize Sample Images</h3>
<p>To get a better sense of the data we&#39;re working with, I&#39;ll look at a few sample images from each class. This helps me verify that the images have been loaded correctly and gives us an idea about the variety and characteristics of the chess pieces that our model will learn to recognise.</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> PIL import Image

<span class="hljs-comment"># Display sample images from each class</span>
fig, axes = plt.subplots(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">12</span>))
for i, (path, <span class="hljs-keyword">label</span><span class="bash">) <span class="hljs-keyword">in</span> enumerate(img_df.sample(9).values):
</span>    img = Image.open(path)
    ax = axes[i//<span class="hljs-number">3</span>, i%<span class="hljs-number">3</span>]
    ax.imshow(img)
    ax.set_title(<span class="hljs-keyword">label</span><span class="bash">)
</span>    ax.axis(<span class="hljs-string">'off'</span>)
plt.tight_layout()
plt.show()
</code></pre>
<p><img src="https://i.imgur.com/8IHtaWA.png" alt="png"></p>
<h1 id="step-3-split-data-into-training-and-testing-sets">Step 3: Split Data into Training and Testing Sets</h1>
<p>The dataset is divided into a larger training set for the model to learn from, and a smaller test set to evaluate the model&#39;s performance on data it hasn&#39;t seen before. This split is essential for validating the model&#39;s ability to generalize.</p>
<p>I resize images to 224x224, which is a standard size for models like VGG16.</p>
<p>The <code>ImageDataGenerator</code> class is a workhorse for augmentation, handling rescaling (normalizing pixel values), horizontal flipping, and other transformations on-the-fly.</p>
<p>The <code>validation_split</code> parameter earmarks 20% of the images for validation purposes, which is useful when we want to assess the model during training.</p>
<pre><code class="lang-python"><span class="hljs-comment"># Split the dataset into training and testing sets</span>
train_df, <span class="hljs-attr">test_df</span> = train_test_split(img_df, <span class="hljs-attr">test_size=0.2,</span> <span class="hljs-attr">random_state=42,</span> <span class="hljs-attr">stratify=img_df['Label'])</span>

print(f<span class="hljs-string">"Training set size: {train_df.shape[0]}"</span>)
print(f<span class="hljs-string">"Testing set size: {test_df.shape[0]}"</span>)
</code></pre>
<pre><code>Training set size: 520
<span class="hljs-keyword">Testing </span>set size: 131
</code></pre><pre><code class="lang-python"><span class="hljs-comment"># Define image dimensions for VGG16</span>
width, <span class="hljs-attr">height</span> = <span class="hljs-number">224</span>, <span class="hljs-number">224</span>

<span class="hljs-comment"># Setup real-time data augmentation parameters</span>
<span class="hljs-attr">datagen</span> = ImageDataGenerator(
    <span class="hljs-attr">rescale=1/255.0,</span>  <span class="hljs-comment"># Normalize image pixel values to [0,1]</span>
    <span class="hljs-attr">horizontal_flip=True,</span> <span class="hljs-comment"># Augment data by flipping images horizontally</span>
    <span class="hljs-attr">rotation_range=20,</span>
    <span class="hljs-attr">width_shift_range=0.1,</span>
    <span class="hljs-attr">height_shift_range=0.1,</span>
    <span class="hljs-attr">zoom_range=0.3,</span>
    <span class="hljs-attr">validation_split=0.2</span>
)
</code></pre>
<h1 id="step-4-model-with-vgg16">Step 4: Model with VGG16</h1>
<p>Using transfer learning, I load the VGG16 model pretrained on ImageNet, without its classification layers (top layers), to leverage its pre-trained convolutional base, ensuring these layers are non-trainable to preserve their learned features.</p>
<p>A new top section is added, designed specifically for the task of classifying five chess piece categories. This includes a Flatten layer, Dense layers with ReLU and softmax activations, and Dropout for regularization.</p>
<p>Then I compile this modified model with a lower learning rate to fine-tune the weights in the newly added layers without significant changes to the pre-trained base.</p>
<pre><code class="lang-python">from tensorflow.keras.applications <span class="hljs-built_in">import</span> VGG16
from tensorflow.keras.layers <span class="hljs-built_in">import</span> Flatten, Dense, Dropout
from tensorflow.keras.models <span class="hljs-built_in">import</span> Model
from tensorflow.keras.optimizers <span class="hljs-built_in">import</span> Adam

def create_model(input_shape):
    <span class="hljs-attr">base_model</span> = VGG16(<span class="hljs-attr">weights='imagenet',</span> <span class="hljs-attr">include_top=False,</span> <span class="hljs-attr">input_shape=input_shape)</span>

    <span class="hljs-comment"># Freeze the layers of the base model</span>
    for layer <span class="hljs-keyword">in</span> base_model.layers:
        layer.<span class="hljs-attr">trainable</span> = False

    <span class="hljs-attr">x</span> = base_model.output
    <span class="hljs-attr">x</span> = Flatten()(x)
    <span class="hljs-attr">x</span> = Dense(<span class="hljs-number">512</span>, <span class="hljs-attr">activation='relu')(x)</span>
    <span class="hljs-attr">x</span> = Dropout(<span class="hljs-number">0.5</span>)(x)  <span class="hljs-comment"># Dropout layer to reduce overfitting</span>
    <span class="hljs-attr">x</span> = Dense(<span class="hljs-number">5</span>, <span class="hljs-attr">activation='softmax')(x)</span>  <span class="hljs-comment"># Final layer with softmax activation for 5 classes</span>

    <span class="hljs-comment"># Combine the base model with the top layers</span>
    <span class="hljs-attr">model</span> = Model(<span class="hljs-attr">inputs=base_model.input,</span> <span class="hljs-attr">outputs=x)</span>

    <span class="hljs-comment"># Compile the model</span>
    model.compile(<span class="hljs-attr">optimizer=Adam(learning_rate=0.0001),</span> <span class="hljs-attr">loss='categorical_crossentropy',</span> <span class="hljs-attr">metrics=['accuracy'])</span>

    return model

<span class="hljs-attr">input_shape</span> = (<span class="hljs-number">224</span>, <span class="hljs-number">224</span>, <span class="hljs-number">3</span>)
<span class="hljs-attr">model</span> = create_model(input_shape)

<span class="hljs-comment"># display the structure of the model</span>
model.summary()
</code></pre>
<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16<span class="hljs-emphasis">_weights_</span>tf<span class="hljs-emphasis">_dim_</span>ordering<span class="hljs-emphasis">_tf_</span>kernels_notop.h5
58889256/58889256 [==============================] - 1s 0us/step
Model: "model"
<span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span>
<span class="hljs-section"> Layer (type)                Output Shape              Param #
=================================================================</span>
 input_1 (InputLayer)        [(None, 224, 224, 3)]     0

block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792

block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928

block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0

block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856

block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584

block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0

block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168

block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080

block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080

block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0

block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160

block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808

block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808

block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0

block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808

block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808

block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808

block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0

flatten (Flatten)           (None, 25088)             0

dense (Dense)               (None, 512)               12845568

dropout (Dropout)           (None, 512)               0

dense_1 (Dense)             (None, 5)                 2565

=================================================================
Total params: 27562821 (105.14 MB)
Trainable params: 12848133 (49.01 MB)
Non-trainable params: 14714688 (56.13 MB)
<span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span><span class="hljs-strong">_____</span>
</code></pre><h1 id="step-5-grad-cam">Step 5: Grad-CAM</h1>
<pre><code class="lang-python">from tensorflow.keras.models <span class="hljs-built_in">import</span> Model
from tensorflow.keras.preprocessing <span class="hljs-built_in">import</span> image
<span class="hljs-built_in">import</span> matplotlib.cm as cm

def get_img_array(img_path, size):
    <span class="hljs-comment"># `img` is a PIL image of size 224x224</span>
    <span class="hljs-attr">img</span> = keras.preprocessing.image.load_img(img_path, <span class="hljs-attr">target_size=size)</span>
    <span class="hljs-attr">array</span> = keras.preprocessing.image.img_to_array(img)
    <span class="hljs-comment"># I add a dimension to transform our array into a "batch"</span>
    <span class="hljs-comment"># of size (1, 224, 224, 3)</span>
    <span class="hljs-attr">array</span> = np.expand_dims(array, <span class="hljs-attr">axis=0)</span>
    return array

def make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names, <span class="hljs-attr">pred_index=None):</span>
    <span class="hljs-attr">grad_model</span> = tf.keras.models.Model(
        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]
    )

    <span class="hljs-keyword">with</span> tf.GradientTape() as tape:
        last_conv_layer_output, <span class="hljs-attr">preds</span> = grad_model(img_array)
        <span class="hljs-keyword">if</span> pred_index is None:
            <span class="hljs-attr">pred_index</span> = tf.argmax(preds[<span class="hljs-number">0</span>])
        <span class="hljs-attr">class_channel</span> = preds[:, pred_index]

    <span class="hljs-attr">grads</span> = tape.gradient(class_channel, last_conv_layer_output)

    <span class="hljs-comment"># This vector is a 2D array with shape</span>
    <span class="hljs-attr">pooled_grads</span> = tf.reduce_mean(grads, <span class="hljs-attr">axis=(0,</span> <span class="hljs-number">1</span>, <span class="hljs-number">2</span>))

    <span class="hljs-attr">last_conv_layer_output</span> = last_conv_layer_output[<span class="hljs-number">0</span>]
    <span class="hljs-attr">heatmap</span> = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
    <span class="hljs-attr">heatmap</span> = tf.squeeze(heatmap)

    <span class="hljs-comment"># For visualization purpose, I will also normalize the heatmap between 0 &amp; 1</span>
    <span class="hljs-attr">heatmap</span> = tf.maximum(heatmap, <span class="hljs-number">0</span>) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()
</code></pre>
<h1 id="step-6-k-fold-cross-validation-setup">Step 6: K-Fold Cross-Validation Setup</h1>
<p>This method splits data into &#39;K&#39; folds, iteratively training the model <code>5</code> times with a different fold as the validation set each time. This reduces overfitting and biases in evaluation metrics.</p>
<pre><code class="lang-python">from sklearn.model_selection <span class="hljs-built_in">import</span> StratifiedKFold
img_df['Path'] = img_df['Path'].astype(str)  <span class="hljs-comment"># Convert 'Path' column to string</span>

<span class="hljs-comment"># Parameters</span>
<span class="hljs-attr">n_splits</span> = <span class="hljs-number">5</span>
<span class="hljs-attr">epochs</span> = <span class="hljs-number">10</span>
<span class="hljs-attr">batch_size</span> = <span class="hljs-number">32</span>

<span class="hljs-comment"># Preparation for K-Fold</span>
<span class="hljs-attr">kfold</span> = StratifiedKFold(<span class="hljs-attr">n_splits=n_splits,</span> <span class="hljs-attr">shuffle=True,</span> <span class="hljs-attr">random_state=42)</span>
<span class="hljs-attr">fold_no</span> = <span class="hljs-number">1</span>
<span class="hljs-attr">input_shape</span> = (<span class="hljs-number">224</span>, <span class="hljs-number">224</span>, <span class="hljs-number">3</span>)

<span class="hljs-comment"># Convert labels to numerical labels</span>
from sklearn.preprocessing <span class="hljs-built_in">import</span> LabelEncoder
<span class="hljs-attr">le</span> = LabelEncoder()
img_df['Encoded_Labels'] = le.fit_transform(img_df['Label'])
<span class="hljs-attr">labels</span> = img_df['Encoded_Labels'].values

for train, test <span class="hljs-keyword">in</span> kfold.split(np.zeros(len(labels)), labels):
    <span class="hljs-attr">train_generator</span> = datagen.flow_from_dataframe(img_df.iloc[train], <span class="hljs-attr">directory=None,</span>
                                                  <span class="hljs-attr">x_col='Path',</span> <span class="hljs-attr">y_col='Label',</span> <span class="hljs-attr">target_size=input_shape[:2],</span>
                                                  <span class="hljs-attr">class_mode='categorical',</span> <span class="hljs-attr">batch_size=batch_size)</span>
    <span class="hljs-attr">validation_generator</span> = datagen.flow_from_dataframe(img_df.iloc[test], <span class="hljs-attr">directory=None,</span>
                                                        <span class="hljs-attr">x_col='Path',</span> <span class="hljs-attr">y_col='Label',</span> <span class="hljs-attr">target_size=input_shape[:2],</span>
                                                        <span class="hljs-attr">class_mode='categorical',</span> <span class="hljs-attr">batch_size=batch_size)</span>
    <span class="hljs-comment"># Reinitialize the model (to start fresh for each fold)</span>
    <span class="hljs-attr">model</span> = create_model(input_shape)

    <span class="hljs-attr">history</span> = model.fit(train_generator, <span class="hljs-attr">epochs=epochs,</span> <span class="hljs-attr">validation_data=validation_generator)</span>

    <span class="hljs-attr">scores</span> = model.evaluate(validation_generator)
    print(f'Score for fold {fold_no}: {model.metrics_names[<span class="hljs-number">0</span>]} of {scores[<span class="hljs-number">0</span>]}; {model.metrics_names[<span class="hljs-number">1</span>]} of {scores[<span class="hljs-number">1</span>]*<span class="hljs-number">100</span>}%')
    fold_no += <span class="hljs-number">1</span>
</code></pre>
<pre><code>Found <span class="hljs-number">520</span> validated image filenames belonging to <span class="hljs-number">5</span> classes.
Found <span class="hljs-number">131</span> validated image filenames belonging to <span class="hljs-number">5</span> classes.
Epoch <span class="hljs-number">1</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 172s 10s/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">1.7611</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.3077</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">1.1056</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.5573</span>
Epoch <span class="hljs-number">2</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 480ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">1.1679</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.5115</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.9959</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.6260</span>
Epoch <span class="hljs-number">3</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 472ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.9439</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.6404</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.8330</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7481</span>
Epoch <span class="hljs-number">4</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 469ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.8201</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7173</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6512</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.8092</span>
Epoch <span class="hljs-number">5</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 489ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.6999</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7462</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6170</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7939</span>
Epoch <span class="hljs-number">6</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 476ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.6184</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7923</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6056</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7863</span>
Epoch <span class="hljs-number">7</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 488ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5629</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8019</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6158</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7939</span>
Epoch <span class="hljs-number">8</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 466ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5422</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8096</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.5592</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7939</span>
Epoch <span class="hljs-number">9</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 479ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5389</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8135</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.5763</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7786</span>
Epoch <span class="hljs-number">10</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 492ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5150</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8231</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.4707</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.8626</span>
<span class="hljs-number">5</span><span class="hljs-regexp">/5 [==============================] - 2s 298ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5271</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8244</span>
Score <span class="hljs-keyword">for</span> fold <span class="hljs-number">1</span>: loss of <span class="hljs-number">0.527118444442749</span>; accuracy of <span class="hljs-number">82.44274854660034</span>%
Found <span class="hljs-number">521</span> validated image filenames belonging to <span class="hljs-number">5</span> classes.
Found <span class="hljs-number">130</span> validated image filenames belonging to <span class="hljs-number">5</span> classes.
Epoch <span class="hljs-number">1</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 11s 563ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">1.6291</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.3762</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">1.1347</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.6308</span>
Epoch <span class="hljs-number">2</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 465ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">1.1131</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.5643</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.9446</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.6462</span>
Epoch <span class="hljs-number">3</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 477ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.8693</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.6775</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.8285</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.6923</span>
Epoch <span class="hljs-number">4</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 471ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.7569</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7159</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.7527</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7615</span>
Epoch <span class="hljs-number">5</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 479ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.6504</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7774</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6804</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7692</span>
Epoch <span class="hljs-number">6</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 475ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5734</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7927</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.7015</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7462</span>
Epoch <span class="hljs-number">7</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 477ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.6079</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7678</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6620</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.8231</span>
Epoch <span class="hljs-number">8</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 471ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5011</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8234</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6079</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.8154</span>
Epoch <span class="hljs-number">9</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 473ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.4485</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8484</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.5881</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.8000</span>
Epoch <span class="hljs-number">10</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 486ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.4205</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8522</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.5488</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.8385</span>
<span class="hljs-number">5</span><span class="hljs-regexp">/5 [==============================] - 2s 320ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5306</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8154</span>
Score <span class="hljs-keyword">for</span> fold <span class="hljs-number">2</span>: loss of <span class="hljs-number">0.5306150913238525</span>; accuracy of <span class="hljs-number">81.53846263885498</span>%
Found <span class="hljs-number">521</span> validated image filenames belonging to <span class="hljs-number">5</span> classes.
Found <span class="hljs-number">130</span> validated image filenames belonging to <span class="hljs-number">5</span> classes.
Epoch <span class="hljs-number">1</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 10s 507ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">1.5570</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.3839</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">1.1130</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.5615</span>
Epoch <span class="hljs-number">2</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 473ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">1.1508</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.5509</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.9489</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.6769</span>
Epoch <span class="hljs-number">3</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 484ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.9137</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.6296</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.7651</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7538</span>
Epoch <span class="hljs-number">4</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 471ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.7540</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7217</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.7810</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7308</span>
Epoch <span class="hljs-number">5</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 477ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.6553</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7793</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.7195</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7077</span>
Epoch <span class="hljs-number">6</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 471ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.6171</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7658</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.7276</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7462</span>
Epoch <span class="hljs-number">7</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 472ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5901</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7965</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6250</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7692</span>
Epoch <span class="hljs-number">8</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 467ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5287</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8330</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6984</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7308</span>
Epoch <span class="hljs-number">9</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 493ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5153</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8349</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.5833</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.8154</span>
Epoch <span class="hljs-number">10</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 476ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.4569</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8464</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.5915</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7923</span>
<span class="hljs-number">5</span><span class="hljs-regexp">/5 [==============================] - 2s 286ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.6194</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7462</span>
Score <span class="hljs-keyword">for</span> fold <span class="hljs-number">3</span>: loss of <span class="hljs-number">0.6193607449531555</span>; accuracy of <span class="hljs-number">74.61538314819336</span>%
Found <span class="hljs-number">521</span> validated image filenames belonging to <span class="hljs-number">5</span> classes.
Found <span class="hljs-number">130</span> validated image filenames belonging to <span class="hljs-number">5</span> classes.
Epoch <span class="hljs-number">1</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 9s 489ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">1.7728</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.3301</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">1.1471</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.6000</span>
Epoch <span class="hljs-number">2</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 475ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">1.1900</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.5163</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.9680</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.6462</span>
Epoch <span class="hljs-number">3</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 475ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.8946</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.6775</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.8641</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7000</span>
Epoch <span class="hljs-number">4</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 478ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.7862</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7102</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.7208</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7308</span>
Epoch <span class="hljs-number">5</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 475ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.6790</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7524</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.7424</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7077</span>
Epoch <span class="hljs-number">6</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 475ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.6815</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7831</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6570</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7538</span>
Epoch <span class="hljs-number">7</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 478ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.6142</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7639</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6241</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7769</span>
Epoch <span class="hljs-number">8</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 472ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5206</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8177</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6424</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7538</span>
Epoch <span class="hljs-number">9</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 473ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.4762</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8464</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6162</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.8154</span>
Epoch <span class="hljs-number">10</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 483ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.4941</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8388</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6388</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7769</span>
<span class="hljs-number">5</span><span class="hljs-regexp">/5 [==============================] - 2s 287ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5340</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8231</span>
Score <span class="hljs-keyword">for</span> fold <span class="hljs-number">4</span>: loss of <span class="hljs-number">0.534013032913208</span>; accuracy of <span class="hljs-number">82.30769038200378</span>%
Found <span class="hljs-number">521</span> validated image filenames belonging to <span class="hljs-number">5</span> classes.
Found <span class="hljs-number">130</span> validated image filenames belonging to <span class="hljs-number">5</span> classes.
Epoch <span class="hljs-number">1</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 10s 519ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">1.6889</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.3033</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">1.2193</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.5385</span>
Epoch <span class="hljs-number">2</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 485ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">1.0246</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.6008</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.9895</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.6462</span>
Epoch <span class="hljs-number">3</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 478ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.8108</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7236</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.9090</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.6462</span>
Epoch <span class="hljs-number">4</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 478ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.7093</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7255</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.8414</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.6769</span>
Epoch <span class="hljs-number">5</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 478ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.6161</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7908</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.7760</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7538</span>
Epoch <span class="hljs-number">6</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 467ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5315</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8330</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.7341</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7538</span>
Epoch <span class="hljs-number">7</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 475ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.5445</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8119</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.8813</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.6615</span>
Epoch <span class="hljs-number">8</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 474ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.4729</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8426</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.7643</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7231</span>
Epoch <span class="hljs-number">9</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 476ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.4103</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8637</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6638</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7462</span>
Epoch <span class="hljs-number">10</span>/<span class="hljs-number">10</span>
<span class="hljs-number">17</span><span class="hljs-regexp">/17 [==============================] - 8s 476ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.4282</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.8599</span> - <span class="hljs-string">val_loss:</span> <span class="hljs-number">0.6356</span> - <span class="hljs-string">val_accuracy:</span> <span class="hljs-number">0.7769</span>
<span class="hljs-number">5</span><span class="hljs-regexp">/5 [==============================] - 2s 305ms/</span>step - <span class="hljs-string">loss:</span> <span class="hljs-number">0.6982</span> - <span class="hljs-string">accuracy:</span> <span class="hljs-number">0.7538</span>
Score <span class="hljs-keyword">for</span> fold <span class="hljs-number">5</span>: loss of <span class="hljs-number">0.6982386112213135</span>; accuracy of <span class="hljs-number">75.38461685180664</span>%
</code></pre><h1 id="step-7-testing-the-model">Step 7: Testing the model</h1>
<p>With the model trained, it&#39;s time to put it to the test on unseen data. This is where we truly assess its performance.</p>
<ul>
<li>First, I confirm that all file paths in the <code>test_df</code> DataFrame are strings to ensure compatibility with our image data generator.</li>
<li>Next, I set up a <code>test_generator</code>, which will feed the test images to our model without shuffling to preserve the order—this is key for an accurate evaluation.</li>
<li>Using this generator, we evaluate the model to obtain the final loss and accuracy metrics on the test data, giving us insight into how well the model generalises beyond the data it was trained on.</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># Define the ImageDataGenerator for the test set (should not include augmentation)</span>
<span class="hljs-attr">test_datagen</span> = ImageDataGenerator(
    <span class="hljs-attr">rescale=1/255.0</span>
)

<span class="hljs-comment"># Ensure the 'Path' column is of type string</span>
test_df['Path'] = test_df['Path'].astype(str)

<span class="hljs-comment"># Create the test_generator using the test_datagen</span>
<span class="hljs-attr">test_generator</span> = test_datagen.flow_from_dataframe(
    <span class="hljs-attr">dataframe=test_df,</span>
    <span class="hljs-attr">x_col='Path',</span>
    <span class="hljs-attr">y_col='Label',</span>
    <span class="hljs-attr">target_size=(224,</span> <span class="hljs-number">224</span>),
    <span class="hljs-attr">batch_size=32,</span>  <span class="hljs-comment"># Experimenting with 16 also</span>
    <span class="hljs-attr">class_mode='categorical',</span>
    <span class="hljs-attr">shuffle=False</span>  <span class="hljs-comment"># Important for evaluation to match predictions with actual labels</span>
)
</code></pre>
<pre><code>Found <span class="hljs-number">131</span> validated image filenames belonging to <span class="hljs-number">5</span> classes.
</code></pre><pre><code class="lang-python"><span class="hljs-comment"># Evaluate the model on the test set</span>
eval_results = model.evaluate(test_generator)
<span class="hljs-built_in">print</span>(f<span class="hljs-string">"Test Loss: {eval_results[0]}, Test Accuracy: {eval_results[1]}"</span>)
</code></pre>
<pre><code>5/5 [==============================] - 1s 71ms/step - loss: 0.2506 - accuracy: 0.9389
<span class="hljs-keyword">Test </span>Loss: 0.25063949823379517, Test Accuracy: 0.9389312863349915
</code></pre><h1 id="step-8-visualizing-the-results-and-confusion-matrix">Step 8: Visualizing the Results and Confusion Matrix</h1>
<h3 id="visualizing-training-results">Visualizing Training Results</h3>
<p>After training the model, we must look at its performance across epochs. These plots help us understand the learning trajectory of the model and pinpoint issues such as overfitting or underfitting.</p>
<pre><code class="lang-python">plt.figure(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">6</span>))
plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)
plt.plot(history.history[<span class="hljs-string">'accuracy'</span>], <span class="hljs-keyword">label</span><span class="bash">=<span class="hljs-string">'Training Accuracy'</span>)
</span>plt.plot(history.history[<span class="hljs-string">'val_accuracy'</span>], <span class="hljs-keyword">label</span><span class="bash">=<span class="hljs-string">'Validation Accuracy'</span>)
</span>plt.title(<span class="hljs-string">'Accuracy over Epochs'</span>)
plt.legend()

plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)
plt.plot(history.history[<span class="hljs-string">'loss'</span>], <span class="hljs-keyword">label</span><span class="bash">=<span class="hljs-string">'Training Loss'</span>)
</span>plt.plot(history.history[<span class="hljs-string">'val_loss'</span>], <span class="hljs-keyword">label</span><span class="bash">=<span class="hljs-string">'Validation Loss'</span>)
</span>plt.title(<span class="hljs-string">'Loss over Epochs'</span>)
plt.legend()

plt.show()
</code></pre>
<p><img src="https://i.imgur.com/da2zjCI.png" alt="png"></p>
<h3 id="confusion-matrix">Confusion Matrix</h3>
<p>A crucial part of model evaluation, especially in classification tasks, is understanding how the model performs for each class. This is where the confusion matrix comes into play. It allows us to visualize the model&#39;s performance across all classes, showing where it may confuse one class for another.</p>
<p>Correct predictions are found along the diagonal, while off-diagonal entries indicate misclassifications.</p>
<pre><code class="lang-python"><span class="hljs-comment"># Predict the test dataset</span>
<span class="hljs-attr">test_predictions</span> = model.predict(test_generator)
<span class="hljs-attr">predicted_classes</span> = np.argmax(test_predictions, <span class="hljs-attr">axis=1)</span>

<span class="hljs-comment"># True labels</span>
<span class="hljs-attr">true_classes</span> = test_generator.classes

<span class="hljs-comment"># Generate the confusion matrix</span>
<span class="hljs-attr">conf_matrix</span> = confusion_matrix(true_classes, predicted_classes)

<span class="hljs-comment"># Plotting the confusion matrix</span>
plt.figure(<span class="hljs-attr">figsize=(10,</span> <span class="hljs-number">8</span>))
sns.heatmap(conf_matrix, <span class="hljs-attr">annot=True,</span> <span class="hljs-attr">fmt='d',</span> <span class="hljs-attr">cmap='Blues',</span> <span class="hljs-attr">xticklabels=le.classes_,</span> <span class="hljs-attr">yticklabels=le.classes_)</span>
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()
</code></pre>
<pre><code><span class="hljs-number">5</span>/<span class="hljs-number">5</span> [==============================] - <span class="hljs-number">1</span>s <span class="hljs-number">86</span>ms/step
</code></pre><p><img src="https://i.imgur.com/gVtNBOd.png" alt="png"></p>
<h1 id="step-9-grad-cam-visualization">Step 9: Grad-Cam Visualization</h1>
<pre><code class="lang-python">from tensorflow.keras.preprocessing.image <span class="hljs-built_in">import</span> img_to_array, load_img
from tensorflow.keras.applications.vgg16 <span class="hljs-built_in">import</span> preprocess_input
from IPython.display <span class="hljs-built_in">import</span> display
from PIL <span class="hljs-built_in">import</span> Image
<span class="hljs-built_in">import</span> matplotlib.pyplot as plt
<span class="hljs-built_in">import</span> numpy as np
<span class="hljs-built_in">import</span> tensorflow as tf

<span class="hljs-attr">img_path</span> = '/content/drive/MyDrive/chessdata/knight-resize/<span class="hljs-number">00000037</span>_resized.jpg'
<span class="hljs-comment"># img_path = '/content/drive/MyDrive/chessdata/knight-resize/00000006_resized.jpg'</span>
<span class="hljs-comment"># img_path = '/content/drive/MyDrive/chessdata/knight-resize/00000030_resized.jpg'</span>
<span class="hljs-comment"># img_path = '/content/drive/MyDrive/chessdata/Rook-resize/00000002_resized.jpg'</span>

<span class="hljs-comment"># Prepare the image</span>
<span class="hljs-attr">img_array</span> = preprocess_input(get_img_array(img_path, img_size))

<span class="hljs-comment"># Print what the top predicted class is</span>
<span class="hljs-attr">preds</span> = model.predict(img_array)
<span class="hljs-attr">predicted_class</span> = np.argmax(preds[<span class="hljs-number">0</span>], <span class="hljs-attr">axis=-1)</span>
<span class="hljs-attr">predicted_class_name</span> = le.classes_[predicted_class]
print(f<span class="hljs-string">"Predicted class: {predicted_class_name}"</span>)

<span class="hljs-comment"># Generate class activation heatmap</span>
<span class="hljs-attr">last_conv_layer_name</span> = 'block5_conv3'
<span class="hljs-attr">classifier_layer_names</span> = ['flatten', 'dense', 'dropout', 'dense_1']
<span class="hljs-attr">heatmap</span> = make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names)

<span class="hljs-comment"># Display heatmap</span>
<span class="hljs-attr">cam_path</span> = <span class="hljs-string">"cam.jpg"</span>  <span class="hljs-comment"># save the grad-cam image</span>
<span class="hljs-attr">alpha</span> = <span class="hljs-number">0.4</span>

def save_and_display_gradcam(img_path, heatmap, <span class="hljs-attr">cam_path="cam.jpg",</span> <span class="hljs-attr">alpha=0.7):</span>
    <span class="hljs-comment"># Load the original image</span>
    <span class="hljs-attr">img</span> = keras.preprocessing.image.load_img(img_path)
    <span class="hljs-attr">img</span> = keras.preprocessing.image.img_to_array(img)

    <span class="hljs-comment"># Rescale heatmap</span>
    <span class="hljs-attr">heatmap</span> = np.uint8(<span class="hljs-number">255</span> * heatmap)

    <span class="hljs-comment"># Use jet colormap to colorize heatmap</span>
    <span class="hljs-attr">colormap</span> = plt.get_cmap(<span class="hljs-string">"jet"</span>)

    <span class="hljs-comment"># Use RGB values of the colormap</span>
    <span class="hljs-attr">jet_colors</span> = colormap(np.arange(<span class="hljs-number">256</span>))[:, :<span class="hljs-number">3</span>]
    <span class="hljs-attr">jet_heatmap</span> = jet_colors[heatmap]

    <span class="hljs-comment"># Create an image with RGB colorized heatmap</span>
    <span class="hljs-attr">jet_heatmap</span> = keras.preprocessing.image.array_to_img(jet_heatmap)
    <span class="hljs-attr">jet_heatmap</span> = jet_heatmap.resize((img.shape[<span class="hljs-number">1</span>], img.shape[<span class="hljs-number">0</span>]))
    <span class="hljs-attr">jet_heatmap</span> = keras.preprocessing.image.img_to_array(jet_heatmap)

    <span class="hljs-comment"># Superimpose the heatmap on original image</span>
    <span class="hljs-attr">superimposed_img</span> = jet_heatmap * alpha + img
    <span class="hljs-attr">superimposed_img</span> = keras.preprocessing.image.array_to_img(superimposed_img)

    superimposed_img.save(cam_path)

    plt.imshow(superimposed_img)
    plt.axis('off')
    plt.show()

save_and_display_gradcam(img_path, heatmap, <span class="hljs-attr">cam_path=cam_path,</span> <span class="hljs-attr">alpha=alpha)</span>
</code></pre>
<pre><code><span class="hljs-number">1</span><span class="hljs-regexp">/1 [==============================] - 0s 26ms/</span><span class="hljs-keyword">step</span>
Predicted <span class="hljs-keyword">class</span>: knight-resize
</code></pre><p><img src="https://i.imgur.com/x3uPZk0.png" alt="png"></p>
<h4 id="other-predictions">Other Predictions</h4>
<p><img src="https://i.imgur.com/lvjYGIi.png" alt="png">
<img src="https://i.imgur.com/lSfz6Dg.png" alt="png">
<img src="https://i.imgur.com/gqSby7c.png" alt="png"></p>
<h1 id="-observations-and-conclusions-cnn">🔍 Observations and Conclusions - CNN</h1>
<p>The model&#39;s training showed a promising trajectory, with high accuracy levels and declining loss, although with slight signs of overfitting as evidenced by validation metrics. The confusion matrix revealed impressive classification rates, with minor confusions between similar-shaped pieces like rooks and queens.</p>
<h3 id="-to-improve-">⚙️ To improve:</h3>
<ul>
<li>Regularization and early stopping may curb overfitting.</li>
<li>Further hyperparameter tuning could refine performance.</li>
</ul>
<blockquote>
<h4 id="-overall-the-model-demonstrates-a-solid-foundation-in-recognizing-chess-pieces-with-high-accuracy-while-there-is-room-for-improvement-to-address-overfitting-and-enhance-the-model-s-ability-to-generalize-the-current-results-are-encouraging-">✅ Overall, the model demonstrates a solid foundation in recognizing chess pieces with high accuracy. While there is room for improvement to address overfitting and enhance the model&#39;s ability to generalize, the current results are encouraging.</h4>
</blockquote>
<h3 id="-knowledge-and-skills-i-acquired-or-reinforced-">🚀 Knowledge and Skills I Acquired or Reinforced:</h3>
<ul>
<li>Understanding and applying transfer learning with VGG16</li>
<li>Implementing K-Fold cross-validation for robust model evaluation</li>
<li>Fine-tuning model architecture and parameters to improve classification performance</li>
<li>Interpreting model performance through accuracy/loss graphs and confusion matrices</li>
<li>Addressing class imbalance with data augmentation strategies</li>
</ul>
<h3 id="-sources-">🔗 Sources:</h3>
<ul>
<li><a href="https://keras.io/guides/transfer_learning/">https://keras.io/guides/transfer_learning/</a></li>
<li><a href="https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md">https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md</a></li>
<li><a href="https://lambdalabs.com/blog/tensorflow-2-0-tutorial-04-early-stopping">https://lambdalabs.com/blog/tensorflow-2-0-tutorial-04-early-stopping</a></li>
</ul>
<hr>
<blockquote>
<p>New Observations and Conclusions section is added for Grad-CAM application.</p>
</blockquote>
<h1 id="-observations-and-conclusions-grad-cam-application">🔍 Observations and Conclusions - Grad-CAM Application</h1>
<p>Applying Grad-CAM to the chess piece CNN model gave me a clear picture of what parts of the chess pieces the model looks at when it makes a guess. The gradation and concentration of colors in the heatmaps are indicative of areas in the image where the model is &#39;looking&#39; to make its predictions.</p>
<h3 id="-what-the-heatmaps-show-">📈 What the Heatmaps Show:</h3>
<p>The heatmaps show that the model pays most attention to the special parts of each chess piece, like the horse&#39;s head for the knight and the top part of the rook. This is a good sign because it means the model is looking at the right things to tell the pieces apart.</p>
<h3 id="-learning-from-grad-cam-visuals-">📈 Learning from Grad-CAM Visuals:</h3>
<p>Grad-CAM has affirmed that the model is, to a large extent, making decisions based on appropriate regions of the chess pieces. This aligns with a high accuracy rate, suggesting a correctly learned feature set. However, it also highlighted areas for potential improvement:</p>
<ul>
<li>There were instances where the heatmaps showed some attention to background areas, which could become problematic in more cluttered or diverse real-world scenarios.</li>
<li>Some heatmaps showed less intensity over the pieces, indicating that the model might be uncertain or less confident in its predictions for those instances.</li>
</ul>
<h3 id="-discussing-the-grad-cam-results-">💬 Discussing the Grad-CAM Results:</h3>
<p>From the application of Grad-CAM, I&#39;ve learned that:</p>
<ul>
<li>The model effectively learns distinguishing features of chess pieces that conform to human visual assessment.</li>
<li>While the model&#39;s performance is high, Grad-CAM&#39;s visual feedback provides a valuable diagnostic tool to identify and rectify instances of misclassification before they lead to potential overfitting.</li>
<li>The consistency in the heatmaps across different instances of the same piece supports the robustness of the learned model.</li>
</ul>
<h3 id="-knowledge-and-skills-i-acquired-or-reinforced-">🚀 Knowledge and Skills I Acquired or Reinforced:</h3>
<ul>
<li>Applying advanced visualization techniques to interpret the decisions of convolutional neural networks.</li>
<li>The capability to analyze the feature focus areas of CNNs, contributing to more explainable AI.</li>
<li>The aptitude to leverage diagnostic tools such as Grad-CAM to refine model performance and trustworthiness.</li>
</ul>
<h1 id="-overall">✅ Overall</h1>
<p>The Grad-CAM visualizations strengthen the trust in the model&#39;s ability to determine and utilize pertinent features from the chess piece images. This reinforces the model&#39;s value and potential deployment in real-world applications, like automated chess game tracking or educational tools for chess enthusiasts. The insights from Grad-CAM also pave the way for continuous model refinement, aiming for a level of precision where every prediction is as explainable as it is accurate.</p>
<h3 id="-sources-">🔗 Sources:</h3>
<ul>
<li><a href="https://arxiv.org/abs/1610.02391">https://arxiv.org/abs/1610.02391</a></li>
<li><a href="https://keras.io/examples/vision/grad_cam/">https://keras.io/examples/vision/grad_cam/</a></li>
</ul>
</body></html>
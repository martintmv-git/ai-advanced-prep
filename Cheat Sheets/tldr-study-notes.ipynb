{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # <b>TLDR Notes:</b> Understanding ML, workflow and tech stack, step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data collection is the first and foundational step in the machine learning pipeline. It involves gathering `raw data` from various sources which could include `sensors, logs, databases, datasets, user inputs,` or `online repositories`. The quality and quantity of collected data can significantly influence the performance of ML models. Techniques range from `simple data scraping` to `complex data streaming`, and technologies often used include SQL for databases, APIs for web services, and specialized hardware for sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "#### This process involves cleaning and transforming raw data into a format that ML algorithms can understand. It's about `handling missing values`, `encoding categorical variables`, `normalizing` or `scaling numerical values`, and `feature engineering`. Tools like `pandas` in Python are commonly used. Proper data preparation can greatly enhance model accuracy and is often considered the most time-consuming part of the ML process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms\n",
    "#### These are the set of rules and techniques that allow computers to find patterns and make decisions based on data. From simple `linear regression` and `decision trees` to `complex neural networks` and `ensemble methods`, each algorithm has its strengths and is chosen based on the specific problem and data type. Libraries like [scikit-learn](https://scikit-learn.org/stable/), [TensorFlow](https://www.tensorflow.org), and [PyTorch](https://pytorch.org) provide implementations of these algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization in ML\n",
    "#### It's a powerful practice to explore and communicate data insights through graphical representation. Tools like [Matplotlib](https://matplotlib.org), [Seaborn](https://seaborn.pydata.org), and [Plotly](https://plotly.com) in Python, or ggplot2 in R, are used to create charts, graphs, and interactive plots. Good visualization helps in understanding complex data, detecting outliers, errors, and patterns, and is crucial for communicating findings to stakeholders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Programming for ML\n",
    "#### Python is a versatile, high-level language widely adopted in machine learning for its simplicity and the extensive availability of libraries and frameworks. Libraries like [NumPy](https://numpy.org) for numerical operations, [pandas](https://pandas.pydata.org) for data manipulation, [scikit-learn](https://scikit-learn.org/stable/) for machine learning, and [TensorFlow](https://www.tensorflow.org) and [PyTorch](https://pytorch.org) for deep learning, form the core stack for ML in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebooks for ML\n",
    "#### Jupyter Notebooks offer an interactive coding environment where you can write and execute code, visualize data, and document the process using Markdown. It's highly favored for ML projects due to its ability to combine code, output, and annotations into a single document, making it ideal for experiments, exploratory data analysis, and educational purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Tech Stack\n",
    "\n",
    "- #### `NumPy` is used for handling numerical operations. Its array objects are much faster and compact than traditional Python lists. NumPy arrays form the core structure that pandas and other libraries build upon.\n",
    "\n",
    "- #### `Pandas` is utilized for data manipulation and analysis. It offers data structures like DataFrames, which make it easy to load, manage, and manipulate tabular data with ease. Pandas is typically used for data cleaning, filtration, and transformation tasks.\n",
    "\n",
    "- #### `Matplotlib` is employed for creating static, interactive, and animated visualizations in Python. It's useful for plotting graphs and charts, which are essential for data exploration and results presentation.\n",
    "\n",
    "- #### Libraries like `Seaborn build on Matplotlib`, offering a higher-level interface for drawing attractive and informative statistical graphics. It's often used alongside pandas for seamless data visualization tasks.\n",
    "\n",
    "- #### `Scikit-learn` is the go-to library for classical machine learning algorithms. It's used for tasks ranging from preprocessing data, feature extraction, and modeling with algorithms like linear regression, decision trees, and clustering.\n",
    "\n",
    "- #### `TensorFlow` is a powerful library for deep learning developed by Google. It's used extensively for constructing and training neural networks with large datasets, often for applications in image and speech recognition, natural language processing, and more.\n",
    "\n",
    "- #### `PyTorch`, created by Meta, is another library for deep learning. It's known for its flexibility and dynamic computational graph, which is particularly friendly for research and development. It allows for easy and fast adjustments to neural networks, making it a preferred choice for experimentation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

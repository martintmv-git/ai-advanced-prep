{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL, Gymnasium, Q-Learning - Cart Pole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup and Requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CartPole class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartPole:\n",
    "    \"\"\"\n",
    "        Wrapper class for CartPole environment\n",
    "\n",
    "        Attributes:\n",
    "            _env: The Gym environment for the Cart Pole game.\n",
    "            _curr_state (np.array): The current state of the environment.\n",
    "            _isTerminated (bool): Flag indicating whether the current episode has ended.\n",
    "    \"\"\"\n",
    "    def __init__(self, is_learning = False):\n",
    "        \"\"\"\n",
    "        Initializes the CartPole environment\n",
    "\n",
    "        Args:\n",
    "            is_learning (bool): Flag to determine if the environment is for learning or visualization.\n",
    "        \"\"\"\n",
    "        # Define whether we want to visualize\n",
    "        if is_learning:\n",
    "            self._env = gym.make('CartPole-v1')\n",
    "        else:\n",
    "            self._env = gym.make('CartPole-v1', render_mode = \"human\")\n",
    "        self._currState = self._env.reset()[0]\n",
    "        self._isTerminated = False\n",
    "\n",
    "\n",
    "    def digitize_state(self, state):\n",
    "        \"\"\"\n",
    "        Digitizes the continuous state into discrete values for Q-table.\n",
    "        \n",
    "        Args:\n",
    "            state (np.array): The current state of the environment.\n",
    "\n",
    "        Returns:\n",
    "            list: A list representing the digitized state.\n",
    "        \"\"\"\n",
    "        pos_space = np.linspace(-2.4, 2.4, 10)\n",
    "        vel_space = np.linspace(-4, 4, 10)\n",
    "        ang_space = np.linspace(-.2095, .2095, 10)\n",
    "        ang_vel_space = np.linspace(-4, 4, 10)\n",
    "        \n",
    "        new_state_p = np.digitize(state[0], pos_space)\n",
    "        new_state_v = np.digitize(state[1], vel_space)\n",
    "        new_state_a = np.digitize(state[2], ang_space)\n",
    "        new_state_av= np.digitize(state[3], ang_vel_space)\n",
    "        new_state_dig = [new_state_p, new_state_v, new_state_a, new_state_av]\n",
    "        return new_state_dig\n",
    "\n",
    "    def do_action(self, action):\n",
    "       \"\"\"\n",
    "        Performs a step in the environment. Gets the values for Observation, reward and checks if the game is over\n",
    "\n",
    "        Args:\n",
    "            action (int): an action passed to the environment\n",
    "        Returns:\n",
    "            new_state: Discrete state after the action is taken\n",
    "            reward: Reward basing on the taken action\n",
    "       \"\"\"\n",
    "       new_state, reward, self._isTerminated, _, _ = self._env.step(action)       \n",
    "       # Update the current state\n",
    "       self._currState = new_state\n",
    "       return self.digitize_state(new_state), reward\n",
    "    \n",
    "    def reset_env(self):\n",
    "        \"\"\" Resets the environment \"\"\"\n",
    "        self._currState = self._env.reset()[0]\n",
    "        self._isTerminated = False\n",
    "\n",
    "    def get_current_state(self):\n",
    "        \"\"\" Gets the discrete state of the environment \"\"\"\n",
    "        return self.digitize_state(self._currState)\n",
    "    \n",
    "    def get_action_space(self):\n",
    "        \"\"\"Returns the size of the action space\"\"\"\n",
    "        return self._env.action_space.n\n",
    "    \n",
    "    def is_game_over(self):\n",
    "        \"\"\" Returns boolean determining if game is over\"\"\"\n",
    "        return self._isTerminated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Q Learning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_learning:\n",
    "    \"\"\"\n",
    "        Implementation of Q-learning algorhitm for the CartPole environment.\n",
    "\n",
    "        Attributes:\n",
    "            _env (cartPoleEnv): Cart Pole env\n",
    "            _gamma (float):   The discount factor\n",
    "            _alpha (float): The learning rate.\n",
    "            _epsilon (float): The exploration rate.\n",
    "            _episodes (int): The number of episodes for training\n",
    "            _is_learning (bool): Flag indicating whether the agent is in learning mode.\n",
    "            _Q_table (np.array): The Q-table, stores state-action values\n",
    "    \"\"\"\n",
    "    def __init__(self, env, gamma, alpha, epsilon, episodes, isLearning = True):\n",
    "        \"\"\"\n",
    "            Initializes Q-learning agent.\n",
    "\n",
    "            Works in two ways. When isLearning flag is set True,\n",
    "            it initializes Q-table as a empty np.array, else it tries to load it from file.\n",
    "            Args:\n",
    "                env (cartPoleEnv): The Cart Pole environment.\n",
    "                gamma (float): The discount factor.\n",
    "                alpha (float): The learning rate.\n",
    "                epsilon (float): The exploration rate.\n",
    "                episodes (int): The number of episodes for training.\n",
    "                isLearning (bool): Flag to determine if the agent is in learning mode.\n",
    "        \"\"\"\n",
    "        self._env = env\n",
    "        self._gamma = gamma\n",
    "        self._alpha = alpha\n",
    "        self._epsilon = epsilon\n",
    "        self._episodes = episodes\n",
    "        self._isLearning = isLearning\n",
    "        self._decayRate = epsilon / episodes\n",
    "\n",
    "        if self._isLearning:\n",
    "            print(f'Learning mode on: training agent on alpha: {self._alpha}, gamma: {self._gamma}, epsilon : {self._epsilon}, with {self._episodes} episodes')\n",
    "        else:\n",
    "            print('Visualization mode on')\n",
    "\n",
    "        # Initialize Q_Table\n",
    "        if self._isLearning: \n",
    "            # State is given as continuous set of variables\n",
    "            # we need to cut it into pieces to be able to learn\n",
    "            # The limits here are the limits for our game to be over\n",
    "            pos_space = np.linspace(-2.4, 2.4, 10)\n",
    "            vel_space = np.linspace(-4, 4, 10)\n",
    "            ang_space = np.linspace(-.2095, .2095, 10) #value in rad\n",
    "            ang_vel_space = np.linspace(-4, 4, 10)\n",
    "            self.Q_table = np.zeros((len(pos_space)+1, len(vel_space)+1, \n",
    "                                    len(ang_space)+1, len(ang_vel_space)+1, self._env.get_action_space())) #11x11x11x11x2\n",
    "        else:\n",
    "            #Load the model\n",
    "            f = open('Q_table.pkl', 'rb')\n",
    "            self.Q_table = pickle.load(f)\n",
    "            f.close()\n",
    "\n",
    "    def policy(self, state):\n",
    "        \"\"\" \n",
    "        Epsilon Greedy Policy\n",
    "\n",
    "        Function works in two modes:\n",
    "            If isLearning is True, decides on random whether to choose random action or\n",
    "            the best action according to the Q_table. The higher epsilon, the higher chance of getting random results\n",
    "            When isLearning is set to False, policy only chooses the values basing on the Q_table.\n",
    "        \n",
    "        Args:\n",
    "            state: Discrete state of the environment\n",
    "        \"\"\"\n",
    "        if self._isLearning and np.random.random() < self._epsilon:\n",
    "            # Choose an action at random with probability epsilon\n",
    "            return random.choice([0,1]) # only two actions - left or right\n",
    "        else:\n",
    "            # Choose the best action accordin to Q_table with probability 1-epsilon\n",
    "            return np.argmax(self.Q_table[state[0], state[1], state[2], state[3], :])\n",
    "\n",
    "    def apply(self):\n",
    "        \"\"\"\n",
    "        Executes Q-learning algorhithm over a specified number of episodes.\n",
    "\n",
    "        This method runs the Q-learning algorithm, updating the Q-table based on the interactions\n",
    "        with the environment. It implements an epsilon-greedy policy for action selection and applies \n",
    "        temporal difference learning for updating the Q-table.\n",
    "        Additionally, the method also handles epsilon decay.\n",
    "         \n",
    "        For exploration over time and prints out the progress every 100 episodes.\n",
    "\n",
    "        The method performs the following steps in each episode:\n",
    "        - Interacts with the environment to obtain states, rewards, and new states.\n",
    "        - Updates the Q-table using the temporal difference\n",
    "        - Applies epsilon decay to gradually shift from exploration to exploitation.\n",
    "        - Tracks and logs the rewards for each episode.\n",
    "\n",
    "        At the end of the training, the updated Q-table is saved to a file (if in learning mode), \n",
    "        and the average reward across all episodes is calculated and printed to the output.\n",
    "        \"\"\"\n",
    "\n",
    "        total_episode_rewards = []  # Rewards of all runs\n",
    "        for episode in range(self._episodes):\n",
    "            episode_rewards = [] # rewards for each episode\n",
    "            rewards = 0\n",
    "            while not self._env.is_game_over():\n",
    "                # get the current state\n",
    "                curr_state = self._env.get_current_state()\n",
    "                action = self.policy(curr_state)\n",
    "                next_state, reward = self._env.do_action(action)\n",
    "                # Choose maximum Q-value for next state\n",
    "                max_next_value = np.max(self.Q_table[next_state[0], next_state[1], next_state[2], next_state[3], :])\n",
    "                # Temporal difference update TODO improve readability\n",
    "                self.Q_table[curr_state[0], curr_state[1], curr_state[2], curr_state[3], action] = self.Q_table[curr_state[0], curr_state[1], curr_state[2], curr_state[3], action] +\\\n",
    "                self._alpha * ( reward + self._gamma * max_next_value -  self.Q_table[curr_state[0], curr_state[1], curr_state[2], curr_state[3], action]) \n",
    "                rewards += reward\n",
    "\n",
    "            # Reset before new episode\n",
    "            self._env.reset_env()\n",
    "\n",
    "            # Epsilon Decay rate \n",
    "            self._epsilon = self._epsilon - self._decayRate\n",
    "            \n",
    "            # Get episode  rewards\n",
    "            total_episode_rewards.append(rewards)\n",
    "            mean_rewards = np.mean(total_episode_rewards[len(total_episode_rewards)-100:])\n",
    "            \n",
    "            if not self._isLearning:\n",
    "                # Display results after each episode\n",
    "                print(f'Episode: {episode} Rewards: {rewards}')\n",
    "            else:\n",
    "                # For every 100 display rewards\n",
    "                if episode % 100 == 0:\n",
    "                    print(f'Episode: {episode} Rewards: {rewards}  Epsilon: {self._epsilon:0.2f}  Mean Rewards {mean_rewards:0.1f}')\n",
    "                    total_episode_rewards.append(np.sum(episode_rewards))\n",
    "            \n",
    "            # Threshold for rewards\n",
    "            if mean_rewards >= 1000:\n",
    "                print(f' Mean rewards: {mean_rewards} - no need to train model longer')\n",
    "                break\n",
    "        \n",
    "        # Save Q table to file\n",
    "        if self._isLearning:\n",
    "            f = open('Q_table.pkl','wb')\n",
    "            pickle.dump(self.Q_table, f)\n",
    "            f.close()\n",
    "\n",
    "        # Calculate the mean\n",
    "        print(\"Average reward after all episodes: \", np.mean(total_episode_rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning mode on: training agent on alpha: 0.1, gamma: 0.7, epsilon : 0.5, with 1000 episodes\n",
      "Episode: 0 Rewards: 10.0  Epsilon: 0.50  Mean Rewards 10.0\n",
      "Episode: 100 Rewards: 21.0  Epsilon: 0.45  Mean Rewards 21.8\n",
      "Episode: 200 Rewards: 26.0  Epsilon: 0.40  Mean Rewards 20.4\n",
      "Episode: 300 Rewards: 17.0  Epsilon: 0.35  Mean Rewards 24.6\n",
      "Episode: 400 Rewards: 20.0  Epsilon: 0.30  Mean Rewards 26.9\n",
      "Episode: 500 Rewards: 25.0  Epsilon: 0.25  Mean Rewards 29.1\n",
      "Episode: 600 Rewards: 25.0  Epsilon: 0.20  Mean Rewards 27.7\n",
      "Episode: 700 Rewards: 35.0  Epsilon: 0.15  Mean Rewards 30.7\n",
      "Episode: 800 Rewards: 37.0  Epsilon: 0.10  Mean Rewards 32.9\n",
      "Episode: 900 Rewards: 32.0  Epsilon: 0.05  Mean Rewards 35.0\n",
      "Average reward after all episodes:  28.114851485148513\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    gamma = 0.7 # Discount rate\n",
    "    alpha = 0.1 # Learning rate\n",
    "    epsilon = 0.5 # How much we want to explore \n",
    "    episodes = 1000 # Number of episodes ; experimented with 5000, 10 000 and 30 000\n",
    "\n",
    "    isLearning = True # Set to True to train the agent\n",
    "\n",
    "    cart_pole = CartPole(isLearning)\n",
    "    agent = Q_learning(cart_pole, gamma, alpha, epsilon, episodes, isLearning)\n",
    "    agent.apply()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization mode on\n",
      "Episode: 0 Rewards: 35.0\n",
      "Episode: 1 Rewards: 37.0\n",
      "Episode: 2 Rewards: 40.0\n",
      "Episode: 3 Rewards: 40.0\n",
      "Episode: 4 Rewards: 36.0\n",
      "Episode: 5 Rewards: 34.0\n",
      "Episode: 6 Rewards: 36.0\n",
      "Episode: 7 Rewards: 41.0\n",
      "Episode: 8 Rewards: 31.0\n",
      "Episode: 9 Rewards: 42.0\n",
      "Episode: 10 Rewards: 32.0\n",
      "Episode: 11 Rewards: 30.0\n",
      "Episode: 12 Rewards: 34.0\n",
      "Episode: 13 Rewards: 42.0\n",
      "Episode: 14 Rewards: 38.0\n",
      "Episode: 15 Rewards: 29.0\n",
      "Episode: 16 Rewards: 29.0\n",
      "Episode: 17 Rewards: 35.0\n",
      "Episode: 18 Rewards: 40.0\n",
      "Episode: 19 Rewards: 39.0\n",
      "Episode: 20 Rewards: 34.0\n",
      "Episode: 21 Rewards: 33.0\n",
      "Episode: 22 Rewards: 36.0\n",
      "Episode: 23 Rewards: 31.0\n",
      "Episode: 24 Rewards: 32.0\n",
      "Episode: 25 Rewards: 32.0\n",
      "Episode: 26 Rewards: 33.0\n",
      "Episode: 27 Rewards: 34.0\n",
      "Episode: 28 Rewards: 39.0\n",
      "Episode: 29 Rewards: 38.0\n",
      "Episode: 30 Rewards: 38.0\n",
      "Episode: 31 Rewards: 44.0\n",
      "Episode: 32 Rewards: 41.0\n",
      "Episode: 33 Rewards: 41.0\n",
      "Episode: 34 Rewards: 37.0\n",
      "Episode: 35 Rewards: 41.0\n",
      "Episode: 36 Rewards: 36.0\n",
      "Episode: 37 Rewards: 41.0\n",
      "Episode: 38 Rewards: 41.0\n",
      "Episode: 39 Rewards: 42.0\n",
      "Episode: 40 Rewards: 32.0\n",
      "Episode: 41 Rewards: 32.0\n",
      "Episode: 42 Rewards: 32.0\n",
      "Episode: 43 Rewards: 38.0\n",
      "Episode: 44 Rewards: 33.0\n",
      "Episode: 45 Rewards: 32.0\n",
      "Episode: 46 Rewards: 39.0\n",
      "Episode: 47 Rewards: 31.0\n",
      "Episode: 48 Rewards: 34.0\n",
      "Episode: 49 Rewards: 34.0\n",
      "Episode: 50 Rewards: 41.0\n",
      "Episode: 51 Rewards: 34.0\n",
      "Episode: 52 Rewards: 41.0\n",
      "Episode: 53 Rewards: 33.0\n",
      "Episode: 54 Rewards: 46.0\n",
      "Episode: 55 Rewards: 32.0\n",
      "Episode: 56 Rewards: 40.0\n",
      "Episode: 57 Rewards: 41.0\n",
      "Episode: 58 Rewards: 33.0\n",
      "Episode: 59 Rewards: 39.0\n",
      "Episode: 60 Rewards: 34.0\n",
      "Episode: 61 Rewards: 30.0\n",
      "Episode: 62 Rewards: 33.0\n",
      "Episode: 63 Rewards: 34.0\n",
      "Episode: 64 Rewards: 33.0\n",
      "Episode: 65 Rewards: 34.0\n",
      "Episode: 66 Rewards: 29.0\n",
      "Episode: 67 Rewards: 35.0\n",
      "Episode: 68 Rewards: 32.0\n",
      "Episode: 69 Rewards: 36.0\n",
      "Episode: 70 Rewards: 40.0\n",
      "Episode: 71 Rewards: 34.0\n",
      "Episode: 72 Rewards: 36.0\n",
      "Episode: 73 Rewards: 35.0\n",
      "Episode: 74 Rewards: 39.0\n",
      "Episode: 75 Rewards: 46.0\n",
      "Episode: 76 Rewards: 37.0\n",
      "Episode: 77 Rewards: 40.0\n",
      "Episode: 78 Rewards: 29.0\n",
      "Episode: 79 Rewards: 32.0\n",
      "Episode: 80 Rewards: 36.0\n",
      "Episode: 81 Rewards: 38.0\n",
      "Episode: 82 Rewards: 34.0\n",
      "Episode: 83 Rewards: 34.0\n",
      "Episode: 84 Rewards: 34.0\n",
      "Episode: 85 Rewards: 39.0\n",
      "Episode: 86 Rewards: 36.0\n",
      "Episode: 87 Rewards: 35.0\n",
      "Episode: 88 Rewards: 41.0\n",
      "Episode: 89 Rewards: 31.0\n",
      "Episode: 90 Rewards: 34.0\n",
      "Episode: 91 Rewards: 30.0\n",
      "Episode: 92 Rewards: 32.0\n",
      "Episode: 93 Rewards: 36.0\n",
      "Episode: 94 Rewards: 32.0\n",
      "Episode: 95 Rewards: 38.0\n",
      "Episode: 96 Rewards: 40.0\n",
      "Episode: 97 Rewards: 36.0\n",
      "Episode: 98 Rewards: 36.0\n",
      "Episode: 99 Rewards: 36.0\n",
      "Episode: 100 Rewards: 38.0\n",
      "Episode: 101 Rewards: 31.0\n",
      "Episode: 102 Rewards: 31.0\n",
      "Episode: 103 Rewards: 36.0\n",
      "Episode: 104 Rewards: 34.0\n",
      "Episode: 105 Rewards: 30.0\n",
      "Episode: 106 Rewards: 36.0\n",
      "Episode: 107 Rewards: 40.0\n",
      "Episode: 108 Rewards: 32.0\n",
      "Episode: 109 Rewards: 35.0\n",
      "Episode: 110 Rewards: 34.0\n",
      "Episode: 111 Rewards: 36.0\n",
      "Episode: 112 Rewards: 34.0\n",
      "Episode: 113 Rewards: 36.0\n",
      "Episode: 114 Rewards: 34.0\n",
      "Episode: 115 Rewards: 36.0\n",
      "Episode: 116 Rewards: 29.0\n",
      "Episode: 117 Rewards: 32.0\n",
      "Episode: 118 Rewards: 32.0\n",
      "Episode: 119 Rewards: 36.0\n",
      "Episode: 120 Rewards: 36.0\n",
      "Episode: 121 Rewards: 29.0\n",
      "Episode: 122 Rewards: 34.0\n",
      "Episode: 123 Rewards: 30.0\n",
      "Episode: 124 Rewards: 38.0\n",
      "Episode: 125 Rewards: 38.0\n",
      "Episode: 126 Rewards: 36.0\n",
      "Episode: 127 Rewards: 34.0\n",
      "Episode: 128 Rewards: 43.0\n",
      "Episode: 129 Rewards: 32.0\n",
      "Episode: 130 Rewards: 32.0\n",
      "Episode: 131 Rewards: 36.0\n",
      "Episode: 132 Rewards: 37.0\n",
      "Episode: 133 Rewards: 38.0\n",
      "Episode: 134 Rewards: 34.0\n",
      "Episode: 135 Rewards: 39.0\n",
      "Episode: 136 Rewards: 36.0\n",
      "Episode: 137 Rewards: 36.0\n",
      "Episode: 138 Rewards: 31.0\n",
      "Episode: 139 Rewards: 30.0\n",
      "Episode: 140 Rewards: 40.0\n",
      "Episode: 141 Rewards: 36.0\n",
      "Episode: 142 Rewards: 38.0\n",
      "Episode: 143 Rewards: 41.0\n",
      "Episode: 144 Rewards: 33.0\n",
      "Episode: 145 Rewards: 30.0\n",
      "Episode: 146 Rewards: 42.0\n",
      "Episode: 147 Rewards: 36.0\n",
      "Episode: 148 Rewards: 34.0\n",
      "Episode: 149 Rewards: 32.0\n",
      "Episode: 150 Rewards: 29.0\n",
      "Episode: 151 Rewards: 40.0\n",
      "Episode: 152 Rewards: 32.0\n",
      "Episode: 153 Rewards: 35.0\n",
      "Episode: 154 Rewards: 40.0\n",
      "Episode: 155 Rewards: 36.0\n",
      "Episode: 156 Rewards: 37.0\n",
      "Episode: 157 Rewards: 33.0\n",
      "Episode: 158 Rewards: 32.0\n",
      "Episode: 159 Rewards: 32.0\n",
      "Episode: 160 Rewards: 34.0\n",
      "Episode: 161 Rewards: 32.0\n",
      "Episode: 162 Rewards: 35.0\n",
      "Episode: 163 Rewards: 30.0\n",
      "Episode: 164 Rewards: 36.0\n",
      "Episode: 165 Rewards: 37.0\n",
      "Episode: 166 Rewards: 33.0\n",
      "Episode: 167 Rewards: 43.0\n",
      "Episode: 168 Rewards: 35.0\n",
      "Episode: 169 Rewards: 32.0\n",
      "Episode: 170 Rewards: 31.0\n",
      "Episode: 171 Rewards: 34.0\n",
      "Episode: 172 Rewards: 34.0\n",
      "Episode: 173 Rewards: 36.0\n",
      "Episode: 174 Rewards: 38.0\n",
      "Episode: 175 Rewards: 32.0\n",
      "Episode: 176 Rewards: 38.0\n",
      "Episode: 177 Rewards: 29.0\n",
      "Episode: 178 Rewards: 42.0\n",
      "Episode: 179 Rewards: 38.0\n",
      "Episode: 180 Rewards: 36.0\n",
      "Episode: 181 Rewards: 34.0\n",
      "Episode: 182 Rewards: 31.0\n",
      "Episode: 183 Rewards: 39.0\n",
      "Episode: 184 Rewards: 41.0\n",
      "Episode: 185 Rewards: 36.0\n",
      "Episode: 186 Rewards: 32.0\n",
      "Episode: 187 Rewards: 29.0\n",
      "Episode: 188 Rewards: 36.0\n",
      "Episode: 189 Rewards: 38.0\n",
      "Episode: 190 Rewards: 32.0\n",
      "Episode: 191 Rewards: 43.0\n",
      "Episode: 192 Rewards: 38.0\n",
      "Episode: 193 Rewards: 35.0\n",
      "Episode: 194 Rewards: 33.0\n",
      "Episode: 195 Rewards: 34.0\n",
      "Episode: 196 Rewards: 41.0\n",
      "Episode: 197 Rewards: 34.0\n",
      "Episode: 198 Rewards: 42.0\n",
      "Episode: 199 Rewards: 34.0\n",
      "Episode: 200 Rewards: 31.0\n",
      "Episode: 201 Rewards: 34.0\n",
      "Episode: 202 Rewards: 35.0\n",
      "Episode: 203 Rewards: 37.0\n",
      "Episode: 204 Rewards: 34.0\n",
      "Episode: 205 Rewards: 37.0\n",
      "Episode: 206 Rewards: 41.0\n",
      "Episode: 207 Rewards: 29.0\n",
      "Episode: 208 Rewards: 39.0\n",
      "Episode: 209 Rewards: 34.0\n",
      "Episode: 210 Rewards: 42.0\n",
      "Episode: 211 Rewards: 29.0\n",
      "Episode: 212 Rewards: 31.0\n",
      "Episode: 213 Rewards: 33.0\n",
      "Episode: 214 Rewards: 40.0\n",
      "Episode: 215 Rewards: 33.0\n",
      "Episode: 216 Rewards: 38.0\n",
      "Episode: 217 Rewards: 30.0\n",
      "Episode: 218 Rewards: 34.0\n",
      "Episode: 219 Rewards: 34.0\n",
      "Episode: 220 Rewards: 41.0\n",
      "Episode: 221 Rewards: 33.0\n",
      "Episode: 222 Rewards: 37.0\n",
      "Episode: 223 Rewards: 33.0\n",
      "Episode: 224 Rewards: 29.0\n",
      "Episode: 225 Rewards: 37.0\n",
      "Episode: 226 Rewards: 39.0\n",
      "Episode: 227 Rewards: 35.0\n",
      "Episode: 228 Rewards: 36.0\n",
      "Episode: 229 Rewards: 31.0\n",
      "Episode: 230 Rewards: 37.0\n",
      "Episode: 231 Rewards: 38.0\n",
      "Episode: 232 Rewards: 30.0\n",
      "Episode: 233 Rewards: 32.0\n",
      "Episode: 234 Rewards: 34.0\n",
      "Episode: 235 Rewards: 29.0\n",
      "Episode: 236 Rewards: 36.0\n",
      "Episode: 237 Rewards: 40.0\n",
      "Episode: 238 Rewards: 31.0\n",
      "Episode: 239 Rewards: 39.0\n",
      "Episode: 240 Rewards: 39.0\n",
      "Episode: 241 Rewards: 37.0\n",
      "Episode: 242 Rewards: 32.0\n",
      "Episode: 243 Rewards: 30.0\n",
      "Episode: 244 Rewards: 38.0\n",
      "Episode: 245 Rewards: 35.0\n",
      "Episode: 246 Rewards: 40.0\n",
      "Episode: 247 Rewards: 36.0\n",
      "Episode: 248 Rewards: 30.0\n",
      "Episode: 249 Rewards: 36.0\n",
      "Episode: 250 Rewards: 31.0\n",
      "Episode: 251 Rewards: 29.0\n",
      "Episode: 252 Rewards: 31.0\n",
      "Episode: 253 Rewards: 39.0\n",
      "Episode: 254 Rewards: 35.0\n",
      "Episode: 255 Rewards: 32.0\n",
      "Episode: 256 Rewards: 34.0\n",
      "Episode: 257 Rewards: 32.0\n",
      "Episode: 258 Rewards: 33.0\n",
      "Episode: 259 Rewards: 38.0\n",
      "Episode: 260 Rewards: 36.0\n",
      "Episode: 261 Rewards: 35.0\n",
      "Episode: 262 Rewards: 39.0\n",
      "Episode: 263 Rewards: 37.0\n",
      "Episode: 264 Rewards: 35.0\n",
      "Episode: 265 Rewards: 29.0\n",
      "Episode: 266 Rewards: 32.0\n",
      "Episode: 267 Rewards: 29.0\n",
      "Episode: 268 Rewards: 39.0\n",
      "Episode: 269 Rewards: 34.0\n",
      "Episode: 270 Rewards: 32.0\n",
      "Episode: 271 Rewards: 32.0\n",
      "Episode: 272 Rewards: 34.0\n",
      "Episode: 273 Rewards: 32.0\n",
      "Episode: 274 Rewards: 32.0\n",
      "Episode: 275 Rewards: 31.0\n",
      "Episode: 276 Rewards: 36.0\n",
      "Episode: 277 Rewards: 31.0\n",
      "Episode: 278 Rewards: 27.0\n",
      "Episode: 279 Rewards: 32.0\n",
      "Episode: 280 Rewards: 29.0\n",
      "Episode: 281 Rewards: 35.0\n",
      "Episode: 282 Rewards: 41.0\n",
      "Episode: 283 Rewards: 30.0\n",
      "Episode: 284 Rewards: 36.0\n",
      "Episode: 285 Rewards: 36.0\n",
      "Episode: 286 Rewards: 34.0\n",
      "Episode: 287 Rewards: 29.0\n",
      "Episode: 288 Rewards: 38.0\n",
      "Episode: 289 Rewards: 36.0\n",
      "Episode: 290 Rewards: 32.0\n",
      "Episode: 291 Rewards: 40.0\n",
      "Episode: 292 Rewards: 32.0\n",
      "Episode: 293 Rewards: 41.0\n",
      "Episode: 294 Rewards: 40.0\n",
      "Episode: 295 Rewards: 30.0\n",
      "Episode: 296 Rewards: 34.0\n",
      "Episode: 297 Rewards: 37.0\n",
      "Episode: 298 Rewards: 39.0\n",
      "Episode: 299 Rewards: 30.0\n",
      "Episode: 300 Rewards: 30.0\n",
      "Episode: 301 Rewards: 37.0\n",
      "Episode: 302 Rewards: 30.0\n",
      "Episode: 303 Rewards: 32.0\n",
      "Episode: 304 Rewards: 32.0\n",
      "Episode: 305 Rewards: 34.0\n",
      "Episode: 306 Rewards: 30.0\n",
      "Episode: 307 Rewards: 31.0\n",
      "Episode: 308 Rewards: 34.0\n",
      "Episode: 309 Rewards: 39.0\n",
      "Episode: 310 Rewards: 38.0\n",
      "Episode: 311 Rewards: 40.0\n",
      "Episode: 312 Rewards: 32.0\n",
      "Episode: 313 Rewards: 37.0\n",
      "Episode: 314 Rewards: 38.0\n",
      "Episode: 315 Rewards: 37.0\n",
      "Episode: 316 Rewards: 36.0\n",
      "Episode: 317 Rewards: 36.0\n",
      "Episode: 318 Rewards: 31.0\n",
      "Episode: 319 Rewards: 38.0\n",
      "Episode: 320 Rewards: 34.0\n",
      "Episode: 321 Rewards: 38.0\n",
      "Episode: 322 Rewards: 39.0\n",
      "Episode: 323 Rewards: 43.0\n",
      "Episode: 324 Rewards: 35.0\n",
      "Episode: 325 Rewards: 34.0\n",
      "Episode: 326 Rewards: 42.0\n",
      "Episode: 327 Rewards: 36.0\n",
      "Episode: 328 Rewards: 32.0\n",
      "Episode: 329 Rewards: 38.0\n",
      "Episode: 330 Rewards: 38.0\n",
      "Episode: 331 Rewards: 29.0\n",
      "Episode: 332 Rewards: 36.0\n",
      "Episode: 333 Rewards: 32.0\n",
      "Episode: 334 Rewards: 35.0\n",
      "Episode: 335 Rewards: 29.0\n",
      "Episode: 336 Rewards: 36.0\n",
      "Episode: 337 Rewards: 37.0\n",
      "Episode: 338 Rewards: 32.0\n",
      "Episode: 339 Rewards: 36.0\n",
      "Episode: 340 Rewards: 37.0\n",
      "Episode: 341 Rewards: 31.0\n",
      "Episode: 342 Rewards: 38.0\n",
      "Episode: 343 Rewards: 34.0\n",
      "Episode: 344 Rewards: 37.0\n",
      "Episode: 345 Rewards: 29.0\n",
      "Episode: 346 Rewards: 40.0\n",
      "Episode: 347 Rewards: 37.0\n",
      "Episode: 348 Rewards: 43.0\n",
      "Episode: 349 Rewards: 29.0\n",
      "Episode: 350 Rewards: 34.0\n",
      "Episode: 351 Rewards: 33.0\n",
      "Episode: 352 Rewards: 43.0\n",
      "Episode: 353 Rewards: 32.0\n",
      "Episode: 354 Rewards: 30.0\n",
      "Episode: 355 Rewards: 36.0\n",
      "Episode: 356 Rewards: 34.0\n",
      "Episode: 357 Rewards: 34.0\n",
      "Episode: 358 Rewards: 38.0\n",
      "Episode: 359 Rewards: 34.0\n",
      "Episode: 360 Rewards: 40.0\n",
      "Episode: 361 Rewards: 31.0\n",
      "Episode: 362 Rewards: 30.0\n",
      "Episode: 363 Rewards: 36.0\n",
      "Episode: 364 Rewards: 32.0\n",
      "Episode: 365 Rewards: 34.0\n",
      "Episode: 366 Rewards: 32.0\n",
      "Episode: 367 Rewards: 39.0\n",
      "Episode: 368 Rewards: 32.0\n",
      "Episode: 369 Rewards: 29.0\n",
      "Episode: 370 Rewards: 31.0\n",
      "Episode: 371 Rewards: 40.0\n",
      "Episode: 372 Rewards: 34.0\n",
      "Episode: 373 Rewards: 32.0\n",
      "Episode: 374 Rewards: 35.0\n",
      "Episode: 375 Rewards: 33.0\n",
      "Episode: 376 Rewards: 38.0\n",
      "Episode: 377 Rewards: 32.0\n",
      "Episode: 378 Rewards: 30.0\n",
      "Episode: 379 Rewards: 30.0\n",
      "Episode: 380 Rewards: 33.0\n",
      "Episode: 381 Rewards: 31.0\n",
      "Episode: 382 Rewards: 29.0\n",
      "Episode: 383 Rewards: 32.0\n",
      "Episode: 384 Rewards: 32.0\n",
      "Episode: 385 Rewards: 39.0\n",
      "Episode: 386 Rewards: 32.0\n",
      "Episode: 387 Rewards: 33.0\n",
      "Episode: 388 Rewards: 40.0\n",
      "Episode: 389 Rewards: 31.0\n",
      "Episode: 390 Rewards: 42.0\n",
      "Episode: 391 Rewards: 44.0\n",
      "Episode: 392 Rewards: 32.0\n",
      "Episode: 393 Rewards: 30.0\n",
      "Episode: 394 Rewards: 38.0\n",
      "Episode: 395 Rewards: 31.0\n",
      "Episode: 396 Rewards: 43.0\n",
      "Episode: 397 Rewards: 35.0\n",
      "Episode: 398 Rewards: 33.0\n",
      "Episode: 399 Rewards: 36.0\n",
      "Episode: 400 Rewards: 36.0\n",
      "Episode: 401 Rewards: 32.0\n",
      "Episode: 402 Rewards: 32.0\n",
      "Episode: 403 Rewards: 38.0\n",
      "Episode: 404 Rewards: 36.0\n",
      "Episode: 405 Rewards: 29.0\n",
      "Episode: 406 Rewards: 34.0\n",
      "Episode: 407 Rewards: 42.0\n",
      "Episode: 408 Rewards: 35.0\n",
      "Episode: 409 Rewards: 29.0\n",
      "Episode: 410 Rewards: 37.0\n",
      "Episode: 411 Rewards: 32.0\n",
      "Episode: 412 Rewards: 33.0\n",
      "Episode: 413 Rewards: 36.0\n",
      "Episode: 414 Rewards: 31.0\n",
      "Episode: 415 Rewards: 39.0\n",
      "Episode: 416 Rewards: 35.0\n",
      "Episode: 417 Rewards: 32.0\n",
      "Episode: 418 Rewards: 42.0\n",
      "Episode: 419 Rewards: 38.0\n",
      "Episode: 420 Rewards: 34.0\n",
      "Episode: 421 Rewards: 34.0\n",
      "Episode: 422 Rewards: 42.0\n",
      "Episode: 423 Rewards: 36.0\n",
      "Episode: 424 Rewards: 34.0\n",
      "Episode: 425 Rewards: 32.0\n",
      "Episode: 426 Rewards: 33.0\n",
      "Episode: 427 Rewards: 32.0\n",
      "Episode: 428 Rewards: 34.0\n",
      "Episode: 429 Rewards: 30.0\n",
      "Episode: 430 Rewards: 34.0\n",
      "Episode: 431 Rewards: 37.0\n",
      "Episode: 432 Rewards: 31.0\n",
      "Episode: 433 Rewards: 32.0\n",
      "Episode: 434 Rewards: 36.0\n",
      "Episode: 435 Rewards: 35.0\n",
      "Episode: 436 Rewards: 37.0\n",
      "Episode: 437 Rewards: 40.0\n",
      "Episode: 438 Rewards: 39.0\n",
      "Episode: 439 Rewards: 31.0\n",
      "Episode: 440 Rewards: 38.0\n",
      "Episode: 441 Rewards: 34.0\n",
      "Episode: 442 Rewards: 33.0\n",
      "Episode: 443 Rewards: 34.0\n",
      "Episode: 444 Rewards: 36.0\n",
      "Episode: 445 Rewards: 36.0\n",
      "Episode: 446 Rewards: 36.0\n",
      "Episode: 447 Rewards: 38.0\n",
      "Episode: 448 Rewards: 36.0\n",
      "Episode: 449 Rewards: 38.0\n",
      "Episode: 450 Rewards: 36.0\n",
      "Episode: 451 Rewards: 30.0\n",
      "Episode: 452 Rewards: 38.0\n",
      "Episode: 453 Rewards: 40.0\n",
      "Episode: 454 Rewards: 38.0\n",
      "Episode: 455 Rewards: 42.0\n",
      "Episode: 456 Rewards: 30.0\n",
      "Episode: 457 Rewards: 38.0\n",
      "Episode: 458 Rewards: 32.0\n",
      "Episode: 459 Rewards: 34.0\n",
      "Episode: 460 Rewards: 34.0\n",
      "Episode: 461 Rewards: 34.0\n",
      "Episode: 462 Rewards: 34.0\n",
      "Episode: 463 Rewards: 29.0\n",
      "Episode: 464 Rewards: 34.0\n",
      "Episode: 465 Rewards: 40.0\n",
      "Episode: 466 Rewards: 34.0\n",
      "Episode: 467 Rewards: 33.0\n",
      "Episode: 468 Rewards: 32.0\n",
      "Episode: 469 Rewards: 38.0\n",
      "Episode: 470 Rewards: 31.0\n",
      "Episode: 471 Rewards: 29.0\n",
      "Episode: 472 Rewards: 40.0\n",
      "Episode: 473 Rewards: 36.0\n",
      "Episode: 474 Rewards: 33.0\n",
      "Episode: 475 Rewards: 32.0\n",
      "Episode: 476 Rewards: 40.0\n",
      "Episode: 477 Rewards: 33.0\n",
      "Episode: 478 Rewards: 31.0\n",
      "Episode: 479 Rewards: 38.0\n",
      "Episode: 480 Rewards: 46.0\n",
      "Episode: 481 Rewards: 34.0\n",
      "Episode: 482 Rewards: 31.0\n",
      "Episode: 483 Rewards: 40.0\n",
      "Episode: 484 Rewards: 39.0\n",
      "Episode: 485 Rewards: 30.0\n",
      "Episode: 486 Rewards: 36.0\n",
      "Episode: 487 Rewards: 41.0\n",
      "Episode: 488 Rewards: 39.0\n",
      "Episode: 489 Rewards: 32.0\n",
      "Episode: 490 Rewards: 34.0\n",
      "Episode: 491 Rewards: 39.0\n",
      "Episode: 492 Rewards: 37.0\n",
      "Episode: 493 Rewards: 33.0\n",
      "Episode: 494 Rewards: 41.0\n",
      "Episode: 495 Rewards: 32.0\n",
      "Episode: 496 Rewards: 36.0\n",
      "Episode: 497 Rewards: 36.0\n",
      "Episode: 498 Rewards: 32.0\n",
      "Episode: 499 Rewards: 36.0\n",
      "Episode: 500 Rewards: 35.0\n",
      "Episode: 501 Rewards: 39.0\n",
      "Episode: 502 Rewards: 38.0\n",
      "Episode: 503 Rewards: 38.0\n",
      "Episode: 504 Rewards: 32.0\n",
      "Episode: 505 Rewards: 30.0\n",
      "Episode: 506 Rewards: 37.0\n",
      "Episode: 507 Rewards: 38.0\n",
      "Episode: 508 Rewards: 36.0\n",
      "Episode: 509 Rewards: 30.0\n",
      "Episode: 510 Rewards: 34.0\n",
      "Episode: 511 Rewards: 34.0\n",
      "Episode: 512 Rewards: 35.0\n",
      "Episode: 513 Rewards: 38.0\n",
      "Episode: 514 Rewards: 34.0\n",
      "Episode: 515 Rewards: 36.0\n",
      "Episode: 516 Rewards: 37.0\n",
      "Episode: 517 Rewards: 38.0\n",
      "Episode: 518 Rewards: 41.0\n",
      "Episode: 519 Rewards: 31.0\n",
      "Episode: 520 Rewards: 30.0\n",
      "Episode: 521 Rewards: 41.0\n",
      "Episode: 522 Rewards: 34.0\n",
      "Episode: 523 Rewards: 39.0\n",
      "Episode: 524 Rewards: 38.0\n",
      "Episode: 525 Rewards: 38.0\n",
      "Episode: 526 Rewards: 38.0\n",
      "Episode: 527 Rewards: 32.0\n",
      "Episode: 528 Rewards: 29.0\n",
      "Episode: 529 Rewards: 32.0\n",
      "Episode: 530 Rewards: 32.0\n",
      "Episode: 531 Rewards: 36.0\n",
      "Episode: 532 Rewards: 39.0\n",
      "Episode: 533 Rewards: 35.0\n",
      "Episode: 534 Rewards: 29.0\n",
      "Episode: 535 Rewards: 36.0\n",
      "Episode: 536 Rewards: 36.0\n",
      "Episode: 537 Rewards: 42.0\n",
      "Episode: 538 Rewards: 32.0\n",
      "Episode: 539 Rewards: 31.0\n",
      "Episode: 540 Rewards: 43.0\n",
      "Episode: 541 Rewards: 32.0\n",
      "Episode: 542 Rewards: 38.0\n",
      "Episode: 543 Rewards: 29.0\n",
      "Episode: 544 Rewards: 39.0\n",
      "Episode: 545 Rewards: 32.0\n",
      "Episode: 546 Rewards: 35.0\n",
      "Episode: 547 Rewards: 33.0\n",
      "Episode: 548 Rewards: 40.0\n",
      "Episode: 549 Rewards: 39.0\n",
      "Episode: 550 Rewards: 43.0\n",
      "Episode: 551 Rewards: 43.0\n",
      "Episode: 552 Rewards: 32.0\n",
      "Episode: 553 Rewards: 32.0\n",
      "Episode: 554 Rewards: 33.0\n",
      "Episode: 555 Rewards: 41.0\n",
      "Episode: 556 Rewards: 30.0\n",
      "Episode: 557 Rewards: 39.0\n",
      "Episode: 558 Rewards: 33.0\n",
      "Episode: 559 Rewards: 38.0\n",
      "Episode: 560 Rewards: 34.0\n",
      "Episode: 561 Rewards: 34.0\n",
      "Episode: 562 Rewards: 31.0\n",
      "Episode: 563 Rewards: 32.0\n",
      "Episode: 564 Rewards: 30.0\n",
      "Episode: 565 Rewards: 40.0\n",
      "Episode: 566 Rewards: 36.0\n",
      "Episode: 567 Rewards: 34.0\n",
      "Episode: 568 Rewards: 29.0\n",
      "Episode: 569 Rewards: 41.0\n",
      "Episode: 570 Rewards: 30.0\n",
      "Episode: 571 Rewards: 40.0\n",
      "Episode: 572 Rewards: 32.0\n",
      "Episode: 573 Rewards: 34.0\n",
      "Episode: 574 Rewards: 41.0\n",
      "Episode: 575 Rewards: 36.0\n",
      "Episode: 576 Rewards: 42.0\n",
      "Episode: 577 Rewards: 32.0\n",
      "Episode: 578 Rewards: 42.0\n",
      "Episode: 579 Rewards: 40.0\n",
      "Episode: 580 Rewards: 31.0\n",
      "Episode: 581 Rewards: 39.0\n",
      "Episode: 582 Rewards: 29.0\n",
      "Episode: 583 Rewards: 34.0\n",
      "Episode: 584 Rewards: 30.0\n",
      "Episode: 585 Rewards: 32.0\n",
      "Episode: 586 Rewards: 32.0\n",
      "Episode: 587 Rewards: 36.0\n",
      "Episode: 588 Rewards: 41.0\n",
      "Episode: 589 Rewards: 39.0\n",
      "Episode: 590 Rewards: 39.0\n",
      "Episode: 591 Rewards: 36.0\n",
      "Episode: 592 Rewards: 37.0\n",
      "Episode: 593 Rewards: 41.0\n",
      "Episode: 594 Rewards: 32.0\n",
      "Episode: 595 Rewards: 38.0\n",
      "Episode: 596 Rewards: 37.0\n",
      "Episode: 597 Rewards: 36.0\n",
      "Episode: 598 Rewards: 39.0\n",
      "Episode: 599 Rewards: 29.0\n",
      "Episode: 600 Rewards: 32.0\n",
      "Episode: 601 Rewards: 32.0\n",
      "Episode: 602 Rewards: 31.0\n",
      "Episode: 603 Rewards: 40.0\n",
      "Episode: 604 Rewards: 44.0\n",
      "Episode: 605 Rewards: 36.0\n",
      "Episode: 606 Rewards: 32.0\n",
      "Episode: 607 Rewards: 34.0\n",
      "Episode: 608 Rewards: 38.0\n",
      "Episode: 609 Rewards: 37.0\n",
      "Episode: 610 Rewards: 32.0\n",
      "Episode: 611 Rewards: 36.0\n",
      "Episode: 612 Rewards: 38.0\n",
      "Episode: 613 Rewards: 40.0\n",
      "Episode: 614 Rewards: 35.0\n",
      "Episode: 615 Rewards: 36.0\n",
      "Episode: 616 Rewards: 36.0\n",
      "Episode: 617 Rewards: 34.0\n",
      "Episode: 618 Rewards: 36.0\n",
      "Episode: 619 Rewards: 40.0\n",
      "Episode: 620 Rewards: 32.0\n",
      "Episode: 621 Rewards: 32.0\n",
      "Episode: 622 Rewards: 37.0\n",
      "Episode: 623 Rewards: 34.0\n",
      "Episode: 624 Rewards: 31.0\n",
      "Episode: 625 Rewards: 38.0\n",
      "Episode: 626 Rewards: 42.0\n",
      "Episode: 627 Rewards: 31.0\n",
      "Episode: 628 Rewards: 32.0\n",
      "Episode: 629 Rewards: 34.0\n",
      "Episode: 630 Rewards: 41.0\n",
      "Episode: 631 Rewards: 32.0\n",
      "Episode: 632 Rewards: 33.0\n",
      "Episode: 633 Rewards: 40.0\n",
      "Episode: 634 Rewards: 37.0\n",
      "Episode: 635 Rewards: 38.0\n",
      "Episode: 636 Rewards: 32.0\n",
      "Episode: 637 Rewards: 30.0\n",
      "Episode: 638 Rewards: 34.0\n",
      "Episode: 639 Rewards: 30.0\n",
      "Episode: 640 Rewards: 39.0\n",
      "Episode: 641 Rewards: 34.0\n",
      "Episode: 642 Rewards: 30.0\n",
      "Episode: 643 Rewards: 32.0\n",
      "Episode: 644 Rewards: 30.0\n",
      "Episode: 645 Rewards: 42.0\n",
      "Episode: 646 Rewards: 40.0\n",
      "Episode: 647 Rewards: 39.0\n",
      "Episode: 648 Rewards: 35.0\n",
      "Episode: 649 Rewards: 34.0\n",
      "Episode: 650 Rewards: 30.0\n",
      "Episode: 651 Rewards: 36.0\n",
      "Episode: 652 Rewards: 29.0\n",
      "Episode: 653 Rewards: 40.0\n",
      "Episode: 654 Rewards: 34.0\n",
      "Episode: 655 Rewards: 35.0\n",
      "Episode: 656 Rewards: 32.0\n",
      "Episode: 657 Rewards: 35.0\n",
      "Episode: 658 Rewards: 37.0\n",
      "Episode: 659 Rewards: 43.0\n",
      "Episode: 660 Rewards: 34.0\n",
      "Episode: 661 Rewards: 38.0\n",
      "Episode: 662 Rewards: 34.0\n",
      "Episode: 663 Rewards: 36.0\n",
      "Episode: 664 Rewards: 32.0\n",
      "Episode: 665 Rewards: 39.0\n",
      "Episode: 666 Rewards: 32.0\n",
      "Episode: 667 Rewards: 30.0\n",
      "Episode: 668 Rewards: 32.0\n",
      "Episode: 669 Rewards: 40.0\n",
      "Episode: 670 Rewards: 36.0\n",
      "Episode: 671 Rewards: 35.0\n",
      "Episode: 672 Rewards: 41.0\n",
      "Episode: 673 Rewards: 40.0\n",
      "Episode: 674 Rewards: 45.0\n",
      "Episode: 675 Rewards: 41.0\n",
      "Episode: 676 Rewards: 42.0\n",
      "Episode: 677 Rewards: 32.0\n",
      "Episode: 678 Rewards: 34.0\n",
      "Episode: 679 Rewards: 29.0\n",
      "Episode: 680 Rewards: 37.0\n",
      "Episode: 681 Rewards: 30.0\n",
      "Episode: 682 Rewards: 37.0\n",
      "Episode: 683 Rewards: 37.0\n",
      "Episode: 684 Rewards: 32.0\n",
      "Episode: 685 Rewards: 40.0\n",
      "Episode: 686 Rewards: 31.0\n",
      "Episode: 687 Rewards: 36.0\n",
      "Episode: 688 Rewards: 32.0\n",
      "Episode: 689 Rewards: 30.0\n",
      "Episode: 690 Rewards: 34.0\n",
      "Episode: 691 Rewards: 34.0\n",
      "Episode: 692 Rewards: 35.0\n",
      "Episode: 693 Rewards: 32.0\n",
      "Episode: 694 Rewards: 29.0\n",
      "Episode: 695 Rewards: 33.0\n",
      "Episode: 696 Rewards: 33.0\n",
      "Episode: 697 Rewards: 31.0\n",
      "Episode: 698 Rewards: 35.0\n",
      "Episode: 699 Rewards: 38.0\n",
      "Episode: 700 Rewards: 34.0\n",
      "Episode: 701 Rewards: 41.0\n",
      "Episode: 702 Rewards: 35.0\n",
      "Episode: 703 Rewards: 36.0\n",
      "Episode: 704 Rewards: 34.0\n",
      "Episode: 705 Rewards: 33.0\n",
      "Episode: 706 Rewards: 39.0\n",
      "Episode: 707 Rewards: 40.0\n",
      "Episode: 708 Rewards: 32.0\n",
      "Episode: 709 Rewards: 32.0\n",
      "Episode: 710 Rewards: 32.0\n",
      "Episode: 711 Rewards: 34.0\n",
      "Episode: 712 Rewards: 34.0\n",
      "Episode: 713 Rewards: 32.0\n",
      "Episode: 714 Rewards: 37.0\n",
      "Episode: 715 Rewards: 31.0\n",
      "Episode: 716 Rewards: 35.0\n",
      "Episode: 717 Rewards: 32.0\n",
      "Episode: 718 Rewards: 36.0\n",
      "Episode: 719 Rewards: 34.0\n",
      "Episode: 720 Rewards: 40.0\n",
      "Episode: 721 Rewards: 35.0\n",
      "Episode: 722 Rewards: 42.0\n",
      "Episode: 723 Rewards: 38.0\n",
      "Episode: 724 Rewards: 34.0\n",
      "Episode: 725 Rewards: 41.0\n",
      "Episode: 726 Rewards: 32.0\n",
      "Episode: 727 Rewards: 37.0\n",
      "Episode: 728 Rewards: 38.0\n",
      "Episode: 729 Rewards: 34.0\n",
      "Episode: 730 Rewards: 42.0\n",
      "Episode: 731 Rewards: 40.0\n",
      "Episode: 732 Rewards: 32.0\n",
      "Episode: 733 Rewards: 39.0\n",
      "Episode: 734 Rewards: 32.0\n",
      "Episode: 735 Rewards: 39.0\n",
      "Episode: 736 Rewards: 34.0\n",
      "Episode: 737 Rewards: 34.0\n",
      "Episode: 738 Rewards: 30.0\n",
      "Episode: 739 Rewards: 37.0\n",
      "Episode: 740 Rewards: 39.0\n",
      "Episode: 741 Rewards: 34.0\n",
      "Episode: 742 Rewards: 32.0\n",
      "Episode: 743 Rewards: 41.0\n",
      "Episode: 744 Rewards: 36.0\n",
      "Episode: 745 Rewards: 36.0\n",
      "Episode: 746 Rewards: 38.0\n",
      "Episode: 747 Rewards: 39.0\n",
      "Episode: 748 Rewards: 35.0\n",
      "Episode: 749 Rewards: 31.0\n",
      "Episode: 750 Rewards: 30.0\n",
      "Episode: 751 Rewards: 32.0\n",
      "Episode: 752 Rewards: 36.0\n",
      "Episode: 753 Rewards: 30.0\n",
      "Episode: 754 Rewards: 37.0\n",
      "Episode: 755 Rewards: 34.0\n",
      "Episode: 756 Rewards: 42.0\n",
      "Episode: 757 Rewards: 40.0\n",
      "Episode: 758 Rewards: 34.0\n",
      "Episode: 759 Rewards: 33.0\n",
      "Episode: 760 Rewards: 42.0\n",
      "Episode: 761 Rewards: 33.0\n",
      "Episode: 762 Rewards: 30.0\n",
      "Episode: 763 Rewards: 36.0\n",
      "Episode: 764 Rewards: 33.0\n",
      "Episode: 765 Rewards: 30.0\n",
      "Episode: 766 Rewards: 36.0\n",
      "Episode: 767 Rewards: 38.0\n",
      "Episode: 768 Rewards: 35.0\n",
      "Episode: 769 Rewards: 31.0\n",
      "Episode: 770 Rewards: 36.0\n",
      "Episode: 771 Rewards: 34.0\n",
      "Episode: 772 Rewards: 39.0\n",
      "Episode: 773 Rewards: 38.0\n",
      "Episode: 774 Rewards: 38.0\n",
      "Episode: 775 Rewards: 42.0\n",
      "Episode: 776 Rewards: 29.0\n",
      "Episode: 777 Rewards: 33.0\n",
      "Episode: 778 Rewards: 40.0\n",
      "Episode: 779 Rewards: 32.0\n",
      "Episode: 780 Rewards: 32.0\n",
      "Episode: 781 Rewards: 42.0\n",
      "Episode: 782 Rewards: 32.0\n",
      "Episode: 783 Rewards: 35.0\n",
      "Episode: 784 Rewards: 36.0\n",
      "Episode: 785 Rewards: 34.0\n",
      "Episode: 786 Rewards: 36.0\n",
      "Episode: 787 Rewards: 36.0\n",
      "Episode: 788 Rewards: 36.0\n",
      "Episode: 789 Rewards: 32.0\n",
      "Episode: 790 Rewards: 31.0\n",
      "Episode: 791 Rewards: 40.0\n",
      "Episode: 792 Rewards: 39.0\n",
      "Episode: 793 Rewards: 33.0\n",
      "Episode: 794 Rewards: 36.0\n",
      "Episode: 795 Rewards: 40.0\n",
      "Episode: 796 Rewards: 32.0\n",
      "Episode: 797 Rewards: 36.0\n",
      "Episode: 798 Rewards: 29.0\n",
      "Episode: 799 Rewards: 35.0\n",
      "Episode: 800 Rewards: 31.0\n",
      "Episode: 801 Rewards: 32.0\n",
      "Episode: 802 Rewards: 37.0\n",
      "Episode: 803 Rewards: 41.0\n",
      "Episode: 804 Rewards: 40.0\n",
      "Episode: 805 Rewards: 36.0\n",
      "Episode: 806 Rewards: 32.0\n",
      "Episode: 807 Rewards: 34.0\n",
      "Episode: 808 Rewards: 29.0\n",
      "Episode: 809 Rewards: 34.0\n",
      "Episode: 810 Rewards: 37.0\n",
      "Episode: 811 Rewards: 42.0\n",
      "Episode: 812 Rewards: 40.0\n",
      "Episode: 813 Rewards: 33.0\n",
      "Episode: 814 Rewards: 34.0\n",
      "Episode: 815 Rewards: 36.0\n",
      "Episode: 816 Rewards: 37.0\n",
      "Episode: 817 Rewards: 35.0\n",
      "Episode: 818 Rewards: 42.0\n",
      "Episode: 819 Rewards: 46.0\n",
      "Episode: 820 Rewards: 40.0\n",
      "Episode: 821 Rewards: 39.0\n",
      "Episode: 822 Rewards: 31.0\n",
      "Episode: 823 Rewards: 33.0\n",
      "Episode: 824 Rewards: 29.0\n",
      "Episode: 825 Rewards: 30.0\n",
      "Episode: 826 Rewards: 36.0\n",
      "Episode: 827 Rewards: 39.0\n",
      "Episode: 828 Rewards: 31.0\n",
      "Episode: 829 Rewards: 35.0\n",
      "Episode: 830 Rewards: 30.0\n",
      "Episode: 831 Rewards: 38.0\n",
      "Episode: 832 Rewards: 39.0\n",
      "Episode: 833 Rewards: 32.0\n",
      "Episode: 834 Rewards: 38.0\n",
      "Episode: 835 Rewards: 33.0\n",
      "Episode: 836 Rewards: 42.0\n",
      "Episode: 837 Rewards: 30.0\n",
      "Episode: 838 Rewards: 30.0\n",
      "Episode: 839 Rewards: 36.0\n",
      "Episode: 840 Rewards: 43.0\n",
      "Episode: 841 Rewards: 33.0\n",
      "Episode: 842 Rewards: 29.0\n",
      "Episode: 843 Rewards: 40.0\n",
      "Episode: 844 Rewards: 36.0\n",
      "Episode: 845 Rewards: 34.0\n",
      "Episode: 846 Rewards: 36.0\n",
      "Episode: 847 Rewards: 31.0\n",
      "Episode: 848 Rewards: 36.0\n",
      "Episode: 849 Rewards: 32.0\n",
      "Episode: 850 Rewards: 30.0\n",
      "Episode: 851 Rewards: 37.0\n",
      "Episode: 852 Rewards: 32.0\n",
      "Episode: 853 Rewards: 32.0\n",
      "Episode: 854 Rewards: 35.0\n",
      "Episode: 855 Rewards: 40.0\n",
      "Episode: 856 Rewards: 32.0\n",
      "Episode: 857 Rewards: 34.0\n",
      "Episode: 858 Rewards: 40.0\n",
      "Episode: 859 Rewards: 40.0\n",
      "Episode: 860 Rewards: 31.0\n",
      "Episode: 861 Rewards: 32.0\n",
      "Episode: 862 Rewards: 32.0\n",
      "Episode: 863 Rewards: 45.0\n",
      "Episode: 864 Rewards: 33.0\n",
      "Episode: 865 Rewards: 34.0\n",
      "Episode: 866 Rewards: 39.0\n",
      "Episode: 867 Rewards: 34.0\n",
      "Episode: 868 Rewards: 38.0\n",
      "Episode: 869 Rewards: 30.0\n",
      "Episode: 870 Rewards: 33.0\n",
      "Episode: 871 Rewards: 37.0\n",
      "Episode: 872 Rewards: 34.0\n",
      "Episode: 873 Rewards: 43.0\n",
      "Episode: 874 Rewards: 41.0\n",
      "Episode: 875 Rewards: 34.0\n",
      "Episode: 876 Rewards: 31.0\n",
      "Episode: 877 Rewards: 35.0\n",
      "Episode: 878 Rewards: 32.0\n",
      "Episode: 879 Rewards: 42.0\n",
      "Episode: 880 Rewards: 37.0\n",
      "Episode: 881 Rewards: 30.0\n",
      "Episode: 882 Rewards: 38.0\n",
      "Episode: 883 Rewards: 30.0\n",
      "Episode: 884 Rewards: 38.0\n",
      "Episode: 885 Rewards: 40.0\n",
      "Episode: 886 Rewards: 33.0\n",
      "Episode: 887 Rewards: 40.0\n",
      "Episode: 888 Rewards: 40.0\n",
      "Episode: 889 Rewards: 30.0\n",
      "Episode: 890 Rewards: 40.0\n",
      "Episode: 891 Rewards: 30.0\n",
      "Episode: 892 Rewards: 34.0\n",
      "Episode: 893 Rewards: 36.0\n",
      "Episode: 894 Rewards: 32.0\n",
      "Episode: 895 Rewards: 36.0\n",
      "Episode: 896 Rewards: 33.0\n",
      "Episode: 897 Rewards: 31.0\n",
      "Episode: 898 Rewards: 35.0\n",
      "Episode: 899 Rewards: 35.0\n",
      "Episode: 900 Rewards: 33.0\n",
      "Episode: 901 Rewards: 33.0\n",
      "Episode: 902 Rewards: 41.0\n",
      "Episode: 903 Rewards: 27.0\n",
      "Episode: 904 Rewards: 36.0\n",
      "Episode: 905 Rewards: 40.0\n",
      "Episode: 906 Rewards: 42.0\n",
      "Episode: 907 Rewards: 29.0\n",
      "Episode: 908 Rewards: 40.0\n",
      "Episode: 909 Rewards: 32.0\n",
      "Episode: 910 Rewards: 39.0\n",
      "Episode: 911 Rewards: 42.0\n",
      "Episode: 912 Rewards: 33.0\n",
      "Episode: 913 Rewards: 42.0\n",
      "Episode: 914 Rewards: 35.0\n",
      "Episode: 915 Rewards: 33.0\n",
      "Episode: 916 Rewards: 37.0\n",
      "Episode: 917 Rewards: 38.0\n",
      "Episode: 918 Rewards: 34.0\n",
      "Episode: 919 Rewards: 33.0\n",
      "Episode: 920 Rewards: 32.0\n",
      "Episode: 921 Rewards: 43.0\n",
      "Episode: 922 Rewards: 34.0\n",
      "Episode: 923 Rewards: 34.0\n",
      "Episode: 924 Rewards: 42.0\n",
      "Episode: 925 Rewards: 29.0\n",
      "Episode: 926 Rewards: 36.0\n",
      "Episode: 927 Rewards: 32.0\n",
      "Episode: 928 Rewards: 38.0\n",
      "Episode: 929 Rewards: 38.0\n",
      "Episode: 930 Rewards: 32.0\n",
      "Episode: 931 Rewards: 36.0\n",
      "Episode: 932 Rewards: 34.0\n",
      "Episode: 933 Rewards: 40.0\n",
      "Episode: 934 Rewards: 41.0\n",
      "Episode: 935 Rewards: 36.0\n",
      "Episode: 936 Rewards: 31.0\n",
      "Episode: 937 Rewards: 30.0\n",
      "Episode: 938 Rewards: 40.0\n",
      "Episode: 939 Rewards: 34.0\n",
      "Episode: 940 Rewards: 40.0\n",
      "Episode: 941 Rewards: 42.0\n",
      "Episode: 942 Rewards: 34.0\n",
      "Episode: 943 Rewards: 36.0\n",
      "Episode: 944 Rewards: 29.0\n",
      "Episode: 945 Rewards: 34.0\n",
      "Episode: 946 Rewards: 38.0\n",
      "Episode: 947 Rewards: 32.0\n",
      "Episode: 948 Rewards: 34.0\n",
      "Episode: 949 Rewards: 38.0\n",
      "Episode: 950 Rewards: 38.0\n",
      "Episode: 951 Rewards: 35.0\n",
      "Episode: 952 Rewards: 32.0\n",
      "Episode: 953 Rewards: 33.0\n",
      "Episode: 954 Rewards: 38.0\n",
      "Episode: 955 Rewards: 33.0\n",
      "Episode: 956 Rewards: 34.0\n",
      "Episode: 957 Rewards: 29.0\n",
      "Episode: 958 Rewards: 42.0\n",
      "Episode: 959 Rewards: 38.0\n",
      "Episode: 960 Rewards: 35.0\n",
      "Episode: 961 Rewards: 43.0\n",
      "Episode: 962 Rewards: 36.0\n",
      "Episode: 963 Rewards: 36.0\n",
      "Episode: 964 Rewards: 41.0\n",
      "Episode: 965 Rewards: 30.0\n",
      "Episode: 966 Rewards: 34.0\n",
      "Episode: 967 Rewards: 36.0\n",
      "Episode: 968 Rewards: 33.0\n",
      "Episode: 969 Rewards: 38.0\n",
      "Episode: 970 Rewards: 34.0\n",
      "Episode: 971 Rewards: 38.0\n",
      "Episode: 972 Rewards: 29.0\n",
      "Episode: 973 Rewards: 46.0\n",
      "Episode: 974 Rewards: 30.0\n",
      "Episode: 975 Rewards: 34.0\n",
      "Episode: 976 Rewards: 38.0\n",
      "Episode: 977 Rewards: 29.0\n",
      "Episode: 978 Rewards: 36.0\n",
      "Episode: 979 Rewards: 42.0\n",
      "Episode: 980 Rewards: 39.0\n",
      "Episode: 981 Rewards: 38.0\n",
      "Episode: 982 Rewards: 30.0\n",
      "Episode: 983 Rewards: 31.0\n",
      "Episode: 984 Rewards: 39.0\n",
      "Episode: 985 Rewards: 35.0\n",
      "Episode: 986 Rewards: 34.0\n",
      "Episode: 987 Rewards: 38.0\n",
      "Episode: 988 Rewards: 33.0\n",
      "Episode: 989 Rewards: 36.0\n",
      "Episode: 990 Rewards: 43.0\n",
      "Episode: 991 Rewards: 29.0\n",
      "Episode: 992 Rewards: 32.0\n",
      "Episode: 993 Rewards: 36.0\n",
      "Episode: 994 Rewards: 35.0\n",
      "Episode: 995 Rewards: 38.0\n",
      "Episode: 996 Rewards: 38.0\n",
      "Episode: 997 Rewards: 32.0\n",
      "Episode: 998 Rewards: 29.0\n",
      "Episode: 999 Rewards: 34.0\n",
      "Average reward after all episodes:  35.213\n"
     ]
    }
   ],
   "source": [
    "# Copy of previous cell with human render visualisation\n",
    "def main():\n",
    "    gamma = 0.7 # Discount rate\n",
    "    alpha = 0.1 # Learning rate\n",
    "    epsilon = 0.5 # How much we want to explore \n",
    "    episodes = 1000 # Number of episodes ; experimented with 5000, 10 000 and 30 000\n",
    "\n",
    "    isLearning = False # Set to False to test the trained agent\n",
    "\n",
    "    cart_pole = CartPole(isLearning)\n",
    "    agent = Q_learning(cart_pole, gamma, alpha, epsilon, episodes, isLearning)\n",
    "    agent.apply()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
